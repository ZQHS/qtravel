# X程旅游

## 第一章 业务需求

### 第一节 旅游行业描述

```
“旅游大数据”是指在旅游的“住行游购娱”六要素领域所产生的数量巨大、快速传播、类型多样相关（有结构和非结构的）、富有价值的数据集合，并且可以通过大数据技术（例如云计算、分布式存储、流运算、大数据算法、NoSQL数据库、SOA结构体系等）进行数据相关性分析和数据可视化，从而使游客消费者的决策更加有效便捷，提高满意度。

旅游大数据除了具有大数据4个基本特点（大量、高速、多样、价值）外，它更加动态、密集，同时旅游行业是信息高度依赖型产业，本身就是大数据最佳的试验田。因此大数据在旅游行业起步时间非常短，但是发展非常迅速。被习大大夸赞的贵州大数据，其中旅游大数据也是其中一大亮点之一。根据统计数据分析，社交媒体上用户产生内容（UGC）超过60%的内容是是与旅游相关。 “旅游大数据”是指在旅游的“住行游购娱”。六要素领域所产生的数量巨大、快速传播、类型多样相关（有结构和非结构的）、富有价值的数据集合，并且可以通过大数据技术进行数据相关性分析和数据可视化，从而使游客消费者的决策更加有效便捷，提高满意度。旅游行业是大数据应用的最佳试验田。
```



### 第二节 应用案例

#### 旅游行业消费数据洞察



用户关键词搜索条件

![](pic\travel_user_search_condition.png)



用户预订时间分布

![](pic\travel_user_preorder_time.png)





用户群体消费特征

![](pic\travel_user_cluster_feature.png)



```
旅游行业消费数据洞察
基于亿级用户的消费行为数据来支持旅游行业的发展趋势，我们不仅要了解获取客户和促进转化的有效途径，更是需要洞察到消费者需求动机、决策流程、以及消费体验和口碑传播的影响力。在如今，随着中国经济的增长，人均可支配收入增多，推动中国旅游行业正式迈入了大众旅游时代，关注他们的来源途径、预订决策流程、消费喜好、入住体验和口碑点评等，这些行为数据的掌握有助于帮助和促进整个旅游行业及其相关其他相关行业的健康发展。

1 用户消费数据洞察
(1) 旅游形式
	统计显示，自助游上升趋势明显
	

(2) 搜索行为
	搜索行为包含了用户的潜在心理需求，如对地理位置、酒店等级、价格或特色服务等等的需求。这些潜在需求往往和消费者的个人属性、消费特征以及外界环境等相关，这往往是消费者预订决策的开端。例如对旅游目的地和关键词的搜索数据进行用户消费习惯的分析并进行用户群体画像或用户画像。
	
	* 目的地搜索
	  统计显示，一线城市依然是酒店目的地搜索量最高的区域，这主要和该城市区域的经济发展状况，以及城市旅游品牌形象和度假服务设施的完善相关联。另外自然风光较好的城市地区也是用户的重点搜索目的地，同时旅游行业受用户消费能力、个人喜好、节假日、气候影响呈现用户的多元选择，如国外旅游、海滨旅游城市、人文景区等等；同时较之以往的以城市景区为最小旅游单位的形式划分逐渐被热门景区、热门商区所取代或成为用户的核心需求。例如杭州西湖湖滨商圈、南京新街口商圈、广州火车东站、天河体育中心、上海陆家嘴金融贸易区、北京天安门、王府井地区等等。
	  搜索频次的相关统计来看，人均搜索频次和搜索总人数之间有时未形成一致性关系，例如厦门虽然在搜索总人数上未进入到前10,但在人均搜索频次上是排名最高的城市，这反映了用户对于不同旅游城市在其心中的比重程度。
	  
	* 关键词搜索
	  关键词搜索为强心智搜索行为，意味着消费者在搜索过程中有着比较明确的目标选择，希望展现结果更加符合其需求，缩短选择预订酒店的时间成本.例如价格、位置距离、酒店级别、所属商圈位置、交通便利度等等。例如在位置距离中，“距离”、“商业区”和“机场车站”的选择依然是排在前列的筛选条件；在星级选择中，“五星/豪华”、“四星/高档”酒店仍然表现的比较耀眼，总占比为76%。另外较之与传统印象中的价格因素在如今的搜索选择中所占比率较低，可以看出用户对价格的敏感度有所降低，甚至出现“花钱买时间“、”花钱买安全“趋势。尽管如此，但大部分用户表示还是会综合酒店位置、星级和评价等因素选择性价比相对高一点的酒店。除此之外，我们还看到用户对酒店特色、酒店品牌、房型/早餐也出现了前所未有的关注度，选择场景更加具有个性化。在酒店特色选择方面，用户更加倾向于选择亲子酒店、浪漫情侣、休闲度假;在设施服务方面，用户更倾向于是否有接送服务和免费停车;酒店SPA也开始成为受欢迎的小众服务。
	  

(3) 浏览行为
	如果说消费者搜索行为与酒店展现、曝光相关，那么消费者浏览行为会关系着旅游产品、交通选择、酒店住宿的转化，目前用户更关注经过评论、查看、比较等形式找到性价比或服务更为优质的产品。
	用户在搜索和浏览过程中，产品是否能进入到用户的候选名单中就变得非常重要，例如酒店的图片内容、点评内容、性价比、地理位置、关键词场景的排名和曝光等等，都会成为影响用户决策的关键因素。
	例如2016.6-2017.6期间，用户经历搜索、浏览、查看、对比之后，在最后一次浏览过程中，分别有53.38%的用户查看1家酒店就直接预订了，相比上一年同期增长了3.12%; 25.61 %的用户查看2~3家酒店之后直接预订，相比上一年同期增长了 1.34%; 12.66%的用户查看了 4~6家酒店之后直接预订，相比上一年同期下降了1.13%。12.81 %的用户依然查看6家以上的酒店之后直接预订，相比上一年同期下降了3.33%。从中可以看出，用户在最后预订决策时表现得非常直接。同时，从搜索、浏览、查看、对比到预订的整个过程中，我们选取了酒店需求量排名前20名的市级行政区酒店的预订前浏览酒店数进行了分析。其中，三亚和香港位居前列，用户从浏览到预订平均分別浏览了79.7家和46.5家酒店；昆明和武汉排名相对靠后，均为17.4家酒店。这主要是和该城市的旅游属性有关，旅游属性越强，消费者决策时间也会变得越长，在下单之前浏览的酒店数量会越多，从而导致酒店之间的竞争变得越激烈。
	

(4) 预订行为
	除了搜索和浏览外，近些年来消费者的预订行为出现了较大转变，提前预订的时间越来越短，预订的时间越来越碎片化,说走就走的特性愈加明显。
	* 提前预定的时间长短
	  根据数据统计显示.已有轺过半数以上的用户会选柽当天预订当天入住，还有26%的用户选择提前1~ 3天预订，提前1周及以上预订的用户占比仅为13%。
	
	* 预定时间段
	  从每天、每周、每年的时间维度来看，消费者产生预订行为的时间段也变得比较均衡，一方面是因为无线技术的发展，手机预订变得更加便捷，消费者的时间变得更加碎片化；另一方面是消费者生活态度发生了较大转变，“率性而为”“及时行乐”的生活态度成了现在生活的一种时尚。
	  【24小时/天】：每天早上9点到晚上11点为消费者的主要工作和休闲时间，也是酒店预订的主要时间段。在这段时间内，下午4点和5点为预订高峰，上午11点和晚上9点为预订次高峰。
	  【7天/周】：每周中，周五为预订高峰，周一到周四预订变化不大，周末反而成为低峰时间段。
	  【12个月/年】：从统计结果中可以看出春季和夏季为酒店预订的高峰期，秋季和冬季除了十一、元旦、春节长假外，预订量相对出现下降趋势，尤其是11月和2月为明显的预订的低谷。
	  
	* 预定天数
	  预定天数反映了用户对该城市旅行的心理预期，同时也反映了用户的旅游属性。例如对酒店需求量排名前20名城市酒店的平均入住时长进行了具体分析。在这20个城市中，60%以上的消费者仅入住一天的城市数超过了一半。昆明、天津、长沙三个城市入住一天的消费者占比分别达到68.2%、67.4%和66.2%。三亚入住一天的占比最低，仅为33.4%,入住五天及以上的占比达到13.3%。从数据上可以看出，商务型城市入住一天的占比要高于旅游型城市。其次，受目的地游玩项目的影响，澳门、香港和厦门相比其他城市在入住两天的占比上位列前三，也说明这三个城市中短途出行较为常见。
	
	* 预定房型
	  在房型选择上，用户普遍关注“床型、是否含早、房间面积、取消政策”，对“是否价格最低”关注度相对降低。根据2017年订单数据统计显示，选择含早房型的用户占据了35.52%；不含早房型的用户占64.48%。同时，根据携程用户调研结果显示，男性用户与女性用户在房型选择上会有一些差异，男性用户比女性用户更加偏爱含早房型，女性用户比男性用户更加关注室内布局和窗外的视野与景观。
	

(5) 点评行为
	参考用户点评，获取口碑推荐，是消费者在购买决策中的重要一环，正向的点评内容和口碑推荐，往往会提升产品购买转化率；反之，降低产品购买的转化率。这使得用户创作的点评内容、分享内容对其他用户的决策购买行为产生着重要的影响。
	* 点评数量及质量分析
	  豪华型酒店平均点评量最高，2016年7月至2017年6月每家酒店平均产生了近1100条点评；其次是高挡型酒店平均每家产生近600条点评。与上一周期相比，各类型的酒店平均点评数都有所降低，豪华型下降幅度最小，下滑幅度最大是非星级型酒店（具体见图17)。从消费者的点评内容分析发现，点评中消费者对酒店体验评价也越来越明确，也就是说点评的质量越来越高，平均一条点评可以分析出近4个酒店要素的体验感。预订酒店时点评是消费者决策因素之一且权重越来越高，而另一面消费者写点评的意愿在降低，酒店应利用一些运营策略平衡好两者之间的冲突,引导消费者有意愿分享入住体验。
	* 点评满意度分析
	  在满意度方面，全国酒店整体呈良好状态。其中，白皮书对20个重点城市酒店的服务、价格、设施、卫生、位置和餐饮六大维度的点评满意度进行详细分析。例如从统计排名【市级行政区六大维度用户满意度】20个城市在酒店各维度上，设施平均满意度为63.49%,较同期有明显提升;酒店的选址备受消费者的肯定，位置平均满意度为91.51%,达到了优的水平；餐饮和价格较同期提升较为明显，平均满意度分别为80.88%、86.74%，服务(89.61 %)和卫生(81.65%)平均满意度几乎和同期持平。同时，从用户的角度出发，还分析了用户重点关注的维度【卫生间卫生、酒店矂音、停车场、网络、床品五个要素获得的平均观点数和平均满意度及同期对比平均观点数与平均满意度】
	  

（6）消费者群体特征分析
	对消费者群体的划分和研究，有助于旅游行业、交通工具、酒店住宿的市场进行定位和细分，明确其服务的消费群体心理需求，并根据不同的消费群体特征提供与之相对应的市场营销策略，提升营销活动的有效性，减少盲目的投入。
	* 90后群体
	  例如近3年来，随着交通出行的多元化、便利化特点，用户出行的年龄结构也在呈现多元化趋势。例如30岁以下用户较去年增长19%，而近1年的新增用户也以30岁以下年轻用户为主(16、17年新注册用户中30岁以下占比56%)；年轻用户的收入水平并不高，但对酒店的心理价位均高于平均水平。
	  
	* 美食类群体
	  对于美食用户的酒店餐饮需求，白皮书随机选取了 1840名有效用户参与了《酒店餐饮需求问卷调查》，其中有74%的用户表示希望能有特色餐厅推荐，43%的用户考虑餐厅打折/优惠券。在酒店餐饮产品的需求上除了早餐和晚餐外，Bruch的需求也是相对较高的餐饮产品。
	  
	* 亲子用户群
	  亲子用户群体普遍在孩子4岁以内完成首次亲子出行，其中一线城市的亲子用户会在孩子更小的时候就带孩子旅行，不同年龄段的孩子呈现的旅游目的地选择也呈现多元化、节假日井喷等现象。另外，由于涉及孩子出行，用户在进行选择决策时考虑的维度优先级别也会不同，在预订酒店这类用户的关注的因素还是普遍集中在地理位置、用户评价和服务质量，对酒店价格的关注较弱；在预订的酒店类型中以五星/豪华型和四星/高档型酒店为主，分别占比为36%和33%;对儿童早餐、儿童游乐设施、儿童泳池以及与其相对应的政策非常关心。
	  
	  
```



#### 酒店住宿行业分析



酒店等级分布

![](pic\travel_pub_level_stat.png)



酒店评分分布

![](pic\travel_pub_score.png)





```
1 酒店住宿行业市场发展趋势
  * 酒店数量和房间数量也出现了相应的增长，平均增长率为7.68%和8.2%
  * 酒店数增速最快的省份地区为：【上海、青海、海南、云南、台湾、甘肃、广东】
  * 在线住宿需求：增长率高达28.8%
  * 在线住宿价格：与上一年同期基本持平
  * 酒店等级选择：
		# 豪华型、高档型酒店和经济型及其他等级酒店增速放缓,分别为(8.99%、9.41%、7.39%)
		# 舒适型酒店市场却增长强劲，供给增长率高达13.41%
		
2 酒店住宿供给分析
 * 酒店供给增长速度： 
 	  # 西北地区发展势头良好，其中青海和甘肃的房间数量增长率分别达到20.5%和12%
 	  # 从城市供给量来看，无论是酒店数量还是房间数量，城市的酒店供给仍然集中在大中型城市。北京在房间数供给量上位居首位，其次为上海和广州
 	  # 在房间供给的增长率上，青岛供给增长率最高，达到了16.0%，其次是郑州和成都；在超一线城市中，上海、广州的增长率均高于北京，分别为12.0%和12.5%
 	  
 * 各等级酒店供给分析：
 	  # 商务型城市经济和舒适型酒店占比较高。例如 郑州、济南的经济型酒店房间占比超过全市酒店房间总数的四分之三。北京、上海、广州、深圳四个超一线城市经济型酒店占比略低，分别为65.1%、59.5%、66.4%和63.8%。
	  # 中档舒适型和高档型酒店房间占比较为接近，例如 苏州、三亚和大连则呈现出高档型酒店房间数占比高于舒适型酒店的趋势。其中苏州高档型酒店房间数占比14.2%，而舒适型酒店房间占比则为11.4%。
	 # 豪华型酒店房间数占，热门旅游地占比较高，例如三亚仍然遥遥领先，达到26.0%。北京的豪华型酒店房间占比稍低（8.8%)，不及上海的11.7%。二线商务型城市豪华型酒店占比则更低，济南占比仅为2.9%
 	
 	  
3 酒店住宿需求分析
  * 整体规律： 酒店在线需求量和增长率与酒店供给区域分布基本匹配。例如 上海酒店需求增长率达到35.2%，其需求总量超过北京成为全国酒店需求量第一位的城市。北京酒店市场整体较为饱和，在供给量增长缓慢的同时，酒店需求的增长率也较为缓慢。
  * 旅游度假城市增速较快：对于一些新兴旅游景区城市，需求增长最快的四个城市分别为：遵义、绵阳、赣州和贵阳，其需求增长率均高于70%  	
```



####  旅游行业流量预测

```
旅游行业流量预测：
2010年上海世博会，我们持续184天进行未来3天和一周的入园人数预测，其中可靠预测了次高峰值——预测96万当天，而实际是106万人入园，是预测机构当中最接近事实的（在此之前，平均每天不到50万入园）。这些数据，我们提供给上海市旅游局、黄浦区旅游局及其他相关单位、旅游企业参考，帮助旅游局及相关部门疏导各入口入园人数、引导旅游团队、提前配备保安警力做参考。

主要是基于团队预约数据（世博团队门票预定预约系统）与实际入园人数，结合人气指数、自然周变动规律、天气因素及团队拉动因素等主要影响因子构建模型预测而得。
```

![](pic\shiboyuan_stat.jpg)



```
旅行社的产品设计出谋划策:
新升级的赴台社如果想做台湾旅游线路，可以先从8日的行程开始考虑，比较容易被大部分赴台游潜在客户所接受；而老的赴台旅行社如果想拓展市场，产品上可以考虑增加彰化的游览行程（彰化原来属于冷门目的地，但2014年冲入台湾旅游城市前十位，可以看出它的游览需求量在明显增长）.

```

![](pic\taiwan_tourism.jpg)



![](pic\china_tourism.jpg)

总结

```
旅游行业与大数据的关联很多，围绕着“住行游购娱”六要素领域所产生的数量进行分析预测，如交通大数据、气象大数据、美食数据、生活消费数据等等
```





#### 用户消费数据洞察数据分析

##### 旅游产品相关

```
(1) 整体运营方面
旅游形式统计并在此基础上进行多维分析
 * 旅游形式统计：整体计算分析出行人群的旅游形式选择(周末游、跟团游、自由行、私家团)的PV、UV统计及费用相关    统计。
 * 旅游形式统计的同比与环比
 * 旅游形式多维统计：整体计算分析出行人群的旅游形式选择(周末游、跟团游、自由行、私家团)的PV、UV统计及费用    相关统计。涉及的多维度选择为【用户性别、年龄、出发地、目的地、群体或单人、国内游或国外游、旅游时间长短】
	  
    
(2) 预定行为分析
根据不同时间周期设置【当天、1天、3天、7天、15天、30天、90天】进行的预订行为数据分析
* 基于预定行为进行趋势分析
  统计未来N天的热门产品、热门目的地、热门景区、热门路线、热门酒店并呈现趋势变化图
* 对于热门趋势的旅游产品进行宣传、优惠活动等营销措施
  统计营销措施的活动效果
    

(3) 用户行为日志分析
用户粘性分析
* 以启动APP或上线统计用户的喜好程度、使用习惯、使用习惯的群体划分(聚类分析)
   	   

用户搜索分析
* 目的地搜索统计： 例如 以【旅游地区、旅游目的地】进行搜索统计PV、UV，旅游目的地TopN
* 关键词搜索统计
   	 统计热门搜索关键词，例如【旅游城市名】、【旅游景区】、【特征词汇：仙境、温泉、美食等】这些可能跨越多个   维度字段，如旅游产品名称、旅游产品标签、旅游景区名称等等
* 过滤方式、排序方式汇总热门组合条件
  结合搜索条件形成热门旅游产品、热门酒店等的热门组合条件并可进行推荐，另外也可基于此数据进行用户画像分析。
   	   

浏览行为分析
* 对不同维度进行浏览行为分析  例如 【产品分类、浏览时长、类似产品对比、对比数量】
   	   	   

点评行为分析
* 统计用户的点评数量。
* 根据点评对旅游产品、景区进行打分评价。
* 根据打分评价对旅游产品进行满意度分析。
   	   	   

用户意向及去向分析
* 产品意向：统计某些产品、酒店的到达情况前的路径过程并可在到达目的页面前N站进行广告设置
* 产品去向：系统对用户进行了推荐处理，统计用户离开目的地页面后的去向分析
```



##### 酒店相关

```
(1) 酒店业务订单数据统计
基于【酒店分类、酒店等级、酒店所属地区、用户年龄、用户性别、酒店标签、入住时长】
 * 酒店业务订单数据多维统计：基于以上维度进行PV、UV统计及费用相关的多维计算分析。

(2) 酒店浏览日志统计
基于【酒店分类、酒店等级、酒店所属地区、酒店标签、酒店品牌】
 * 酒店浏览数据多维统计：基于以上维度进行PV、UV统计统计分析。

(3) 用户搜索分析
* 常用选择过滤条件
	主题分类：商业区、机场/火车站、大学等
	评分标准：4.5分以上
	星界标准：3星+
	价格区间：300-450
	点评数量： 1000+
	品牌选择： 如家、汉庭等
	酒店类型： 快捷连锁、高端连锁、客栈等
	特色标签： 温泉酒店、亲子酒店
* 基于用户画像在相似用户间进行推荐
* 形成用酒店住宿的户群体画像
  

(4) 酒店点评
* 统计用户的点评数量。
* 根据点评对酒店进行打分评价。
* 根据打分评价对酒店进行满意度分析。
```



##### 票务相关

```
(1) 票务搜索统计
火车票
	* 基于【出发地、目的地、出发日期、车型(KT|D|G)、座席类别(商务座、一等、二等、软卧、硬卧、硬座)】统计【出发地 -> 目的地】间的热门车次、热点日期
	* 意向目的地统计及趋势
	
飞机票
	* 基于【出发地、目的地、出发日期、航空公司、机型(大型机、中型机)、舱位(头等舱、经济舱)】统计【出发地 -> 目的地】间的热门班次、热点日期
	* 意向目的地统计及趋势

(2) 票务订单统计
火车票
	* 基于【出发地、目的地、出发日期、车型(KT|D|G)、座席类别(商务座、一等、二等、软卧、硬卧、硬座)、用户性别、用户年龄】统计人数、费用
	* 同一出发地的目的地去向统计
	
飞机票
	* 基于【出发地、目的地、出发日期、航空公司、机型(大型机、中型机)、舱位(头等舱、经济舱)、用户性别、用户年龄】统计人数、费用
	* 同一出发地的目的地去向统计
```







### 第三节 行业特征

- 用户数量：近亿级

```
【携程】  亿级 
【去哪儿】 亿级
【飞猪】   千万级
【马蜂窝】 千万级 
【途牛】   千万级
```

活跃用户：千万级

```
【携程】  千万级(5588万) 
【去哪儿】 千万级(4133万)
【飞猪】   千万级(2888万)
【马蜂窝】 千万级(2294万)
【途牛】   近千万级(944万)
```



- 数据量级

​	 请求级别：亿级 每天TB级的增量数据，近百亿条的用户数据，上百万的产品数据



- 集群规模

  万台+ | 千台+

  

- 生活娱乐类服务场景APP

  用户交易订单不会高频率呈现，但会集中于个别时间节点(如公共假期、周末、寒暑假等)

  旅游行业作为综合性产业覆盖了：住宿、餐饮、购物、交通等其他相关行业，多元化结合

  用户交互信息数量巨大，而且会涉及其他社交类APP的使用



- 核心业务介绍

```
1 旅游产品业务
2 相关业务：车票、酒店等紧密关系业务
3 用户交互
	3.1 用户行为
		* 评论
		* 点赞
		* 分享、转发
		* 收藏
		* 关注
	3.2 用户与用户
		* 关注、推荐、邀请（关系：好友、粉丝）
		* 圈子
4 消息
	4.1 系统推荐（活动、推广）
	4.2 用户间消息
	
5 画像
	用户群体画像
	用户画像

6 运营
	* 用户层次定位、用户构成
	* 用户粘性：DAU|MAU
	* 各种离线、实时统计指标
	* 各种业务的实时推荐
```





## 第二章 技术架构

### 技术架构图



![](pic\travel_bigdata_platform.png)





### 实时场景数据处理流程图



![](pic\realtime_olap.png)







### 技术框架构成说明

```
一 数据采集
	1  埋点数据： 
		   由微服务后台以发送消息形式采集各种埋点数据
		   Flume日志采集
	2  业务数据： 
		   (1) 基于MYSQL的binlog日志
		   (2) 由微服务后台以消息形式发送
    3  外部接口数据：
    		由微服务后台进行相关处理保存在关系型数据库中或以消息形式发送(为了流量削峰)

二 数据通道
		考虑到高并发下的数据级量采用分布式消息队列 Kafka

三 数据计算
		离线： Spark
		实时： Flink
		交互式查询：
			(1) 实时明细 Druid
			(2) 实时聚合 Druid | Redis
			(3) 实时明细搜索 ES
			(4) 通用型 ClickHouse
			(5) 离线指标 Hive（数仓的集市数据或在此基础上的二次加工）
			(6) 离线或实时的多维分析结果 Kylin
四 任务调度
		Azkaban | airflow
		

五 数据存储
		离线： Hive | HBase | ES
		实时：	Druid | ES
		关联关系： Neo4j | JanusGraph
		
六 数据展示：
		离线展示： echars | apache superset
		实时展示： Grafana
```





## 第三章 数据来源

### 第一节 原始数据

#### <font color="red">旅游相关</font>

##### 用户行为日志

```
行为类型：
 	action： 'launch启动| interactive交互| page_enter页面曝光(产品页展示)',
事件类型：
  	eventType： 'view浏览（多产品）| slide滑动 (多产品)|click点击(收藏|点赞|分享)',
用户ID：(在一些场景下，平台会为用户构造的唯一编号)
	userID
所属设备号(app端的手机设备号)：
	userDevice
设备类型：
	userDeviceType: '1 android| 2 ios | 9 其他'
操作系统：
	os
手机制造商：
	manufacturer
电信运营商：
	carrier
网络类型：
	networkType
所在区域：
	userRegion
所在区域IP:
	userRegionIP
经度:
	longitude
纬度:
	latitude
扩展信息
	exts
事件发生时间：
	ct
```



数据表

```sql
create external table if not exists ods_travel.ods_travel_user_log (
 action string COMMENT '行为类型',
 eventType string COMMENT '事件类型',
 userID string COMMENT '用户ID', 
 userDevice string COMMENT 'app端的手机设备号',   
 os string COMMENT '手机操作系统',
 manufacturer string COMMENT '手机制造商',
 carrier string COMMENT '电信运营商',
 networkType string COMMENT '网络类型',
 userRegion string COMMENT '用户所在区域',
 userRegionIP string COMMENT '用户所在区域IP',
 longitude string COMMENT '经度',
 latitude string COMMENT '纬度', 
 exts string COMMENT '扩展信息'   
 ct bigint COMMENT '日志时间'
) partitioned by (bdp_day string)
stored as parquet
location '/data/qf/travel/ods/ods_travel_user_log/'
```





###### 行为事件说明

```java
#action行为种类：
LAUNCH("02", "launch","加载"),
INTERACTIVE("05", "interactive","交互行为"),
PAGE_ENTER_NATIVE("08", "page_enter_native","页面进入")

#event_type事件类型：
VIEW("01", "view","浏览"),
CLICK("02", "click","点击"),
INPUT("03", "input","输入"),
SLIDE("04", "slide","滑动")
    
#事件的行为目的
PRODUCT_KEEP("101", "收藏"),
PRODUCT_APPLAUD("102", "点赞"),
PRODUCT_SHARE("103", "分享"),
PRODUCT_COMMENT("104", "点评"),
PRODUCT_CS("105", "客服");
```



行为事件种类说明：

(1) 启动日志

```
action=02 #注释：(launch启动)
eventType=无交互事件
exts=无扩展信息
```

示例

```json
{
	"os":"1",
	"lonitude":"115.27267",
	"userRegion":"130533",
	"latitude":"36.90133",
	"eventType":"",
	"userID":"85662",
	"sid":"20200103153500jdjqx",
	"manufacturer":"09",
	"duration":"38",
	"ct":"1578036900000",
	"carrier":"3",
	"userRegionIP":"27.32.4.174",
	"userDeviceType":"9",
	"KAFKA_ID":"a4hm6akmmj",
	"action":"02",
	"userDevice":"51822",
	"networkType":"1",
	"exts":""
}
```



(2) 页面浏览日志

```
action=07 | 08 #注释：page_enter_native 08 | page_enter_h5 07 产品页面进入
eventType= 01 #注释： view 浏览
exts={
	targetID: [目标页面]
}
```

示例

```json
{
	"os":"1",
	"lonitude":"115.27267",
	"userRegion":"130533",
	"latitude":"36.90133",
	"eventType":"01",
	"userID":"85662",
	"sid":"20200103153500jdjqx",
	"manufacturer":"09",
	"duration":"38",
	"ct":"1578036900000",
	"carrier":"3",
	"userRegionIP":"27.32.4.174",
	"userDeviceType":"9",
	"KAFKA_ID":"a4hm6akmmj",
	"action":"08",
	"userDevice":"51822",
	"networkType":"1",
	"exts":"{"targetID":"P1"}"
}
```



(3) 交互式日志

(3-1) 点击日志

```
action=05 #注释：interactive 交互式
eventType=02 #注释：click 点击
exts={
	targetID: [目标页面]
	eventTargetType: [目标动作类型（关注、点评、分享、收藏）]
}
```

示例

```json
{
    "os": "2",
    "lonitude": "101.27417",
    "userRegion": "532823",
    "latitude": "21.45517",
    "eventType": "02",
    "userID": "32444",
    "sid": "20200103153500rgnuk",
    "manufacturer": "01",
    "duration": "0",
    "ct": "1578036900000",
    "carrier": "1",
    "userRegionIP": "67.77.242.139",
    "userDeviceType": "9",
    "KAFKA_ID": "74fk16e7bh",
    "action": "05",
    "userDevice": "94168",
    "networkType": "0",
    "exts": "{
		"eventTargetType":"101",
		"targetID":"P46"
	}"
}
```



(3-2) 产品列表浏览日志

```
action=05 #注释：interactive 交互式
event_type=01 | 04 #注释： view浏览|slide滑动
extinfo={
	targetIDS: [目标页面列表]
	productType: [产品类型：跟团、私家、半自助等]
	productLevel: [产品钻级 1-5]
	travelTime: [行程天数]
    travelSendTime: [出发时间]
    travelSend: [出发地]      		
}
```

示例

```json
{
    "os": "1",
    "lonitude": "105.72017",
    "userRegion": "520381",
    "latitude": "28.45833",
    "eventType": "01",
    "userID": "59229",
    "sid": "20200103153500rkfxn",
    "manufacturer": "09",
    "duration": "54",
    "ct": "1578036900000",
    "carrier": "1",
    "userRegionIP": "64.234.5.53",
    "userDeviceType": "2",
    "KAFKA_ID": "ne31j8m79k",
    "action": "05",
    "userDevice": "25941",
    "hotTarget": "530829", 热门目的地
    "networkType": "3",
    "exts": "{
			"travelSendTime":"202002",
			"travelTime":"9",
			"productLevel":"4",
			"targetIDS":"["P40","P46","P28","P62"]",
			"travelSend":"520381",
			"productType":"01"
	}"
}
```



##### 旅游产品订单

```
用户ID：(在一些场景下，平台会为用户构造的唯一编号)
	user_id
用户手机号：
	user_mobile
旅游产品编号：
	product_id: "598459284410"
旅游产品交通资源：
	product_traffic: 旅游交通选择
旅游产品交通资源：座席
	product_traffic_grade： 商务|一等|软卧...
旅游产品交通资源：行程种类
	product_traffic_type：单程|往返
旅游产品住宿资源：
	product_pub: 旅游住宿选择
所在区域：
	user_region
人员构成_成人人数：
	travel_member_adult
人员构成_儿童人数：
	travel_member_yonger
人员构成_婴儿人数：
	travel_member_baby
产品价格：
	product_price
活动特价	
	has_activity：0无活动特价|其他为折扣率如0.8
产品费用：
	product_fee
下单时间：
	order_ct
```



数据表

```sql
create external table if not exists ods_travel.ods_travel_orders (
 user_id string COMMENT '用户ID', 
 user_mobile string COMMENT '用户手机号',
 product_id string COMMENT '旅游产品编号',
 product_traffic string COMMENT '旅游产品交通资源',
 product_traffic_grade string COMMENT '旅游产品交通:座席', 
 product_traffic_type string COMMENT '旅游产品交通:行程种类',   
 product_pub string COMMENT '旅游产品住宿资源', 
 user_region string COMMENT '用户所在区域',  
 travel_member_adult int COMMENT '人员构成_成人人数',
 travel_member_yonger int COMMENT '人员构成_儿童人数',
 travel_member_baby int COMMENT '人员构成_婴儿人数', 
 product_price double COMMENT '产品价格', 
 has_activity double COMMENT '活动特价',   
 product_fee double COMMENT '产品费用', 
 order_ct bigint COMMENT '日志时间'
) partitioned by (bdp_day string)
stored as parquet
location '/data/qf/travel/ods/ods_travel_orders/'
```



##### 旅游产品支付

```
用户ID：(在一些场景下，平台会为用户构造的唯一编号)
	user_id
旅游产品编号：
	product_Id: "598459284410"
支付费用：
	pay_fee
支付方式：
	pay_type 微信|支付宝|银联等等
支付网络：
	pay_network 4G|wifi
支付时间：
	pay_ct
支付结果：
	pay_result
```



数据表

```sql
create external table if not exists ods_travel.ods_travel_orders_add (
 user_id string COMMENT '用户ID', 
 product_id string COMMENT '旅游产品编号',
 pay_fee double COMMENT '支付费用',    
 pay_type string COMMENT '支付方式',
 pay_network string COMMENT '支付使用网络',
 pay_result string COMMENT '支付结果', 
 pay_ct bigint COMMENT '支付时间'
) partitioned by (bdp_day string)
stored as parquet
location '/data/qf/travel/ods/ods_travel_orders_add/'
```



#### <font color="red">评论相关</font>

###### 评论相关说明

```
评论数据由评论人（用户）、评分、评分项、评论内容、评论时间这几部分构成，其中需要说明的是评分项，不同的业务数据（旅游产品、酒店、景区）的评论项不同
```

评论项示例：

***旅游产品评论***

跟团游(三亚)：【行程安排】、【描述相符】、【导游讲解】

![](pic\common_product_gentuan.png)



自由行(大理)：【旅行交通】、【酒店住宿】、【附加产品】、【推荐玩法】

![](pic\common_product_ziyouxing.png)



***酒店评论***

国内酒店评论：【环境】、【设施】、【服务】、【卫生】

![](pic\common_pub_guonei.png)

国外酒店评论：【环境】、【设施】、【服务】、【卫生】

![](pic\common_pub_guowai.png)



***景区评论***

景区评论：只有评分一项

![](pic\common_scenic.png)





##### 旅游产品评论

```
用户：
	user_id
产品ID:
	product_id
评分：
	common_score
评分项：
	common_exts
评论时间：
	common_ct
评论内容：
	common_remark
```



数据表

```sql
create external table if not exists ods_travel.ods_travel_product_common (
 user_id string COMMENT '用户ID', 
 product_id string COMMENT '旅游产品编号',
 common_score double COMMENT '评分',    
 common_exts string COMMENT '评分项',
 common_remark string COMMENT '评论内容', 
 common_ct bigint COMMENT '评论时间'
) partitioned by (bdp_day string)
stored as parquet
location '/data/qf/travel/ods/ods_travel_product_common/'
```



##### 酒店评论

```
用户：
	user_id
酒店ID:
	pub_id
评分：
	common_score
评分项：
	common_exts
评论时间：
	common_ct
评论内容：
	common_remark
```



数据表

```sql
create external table if not exists ods_travel.ods_travel_pub_common (
 user_id string COMMENT '用户ID', 
 pub_id string COMMENT '酒店编号',
 common_score double COMMENT '评分',    
 common_exts string COMMENT '评分项',
 common_remark string COMMENT '评论内容', 
 common_ct bigint COMMENT '评论时间'
) partitioned by (bdp_day string)
stored as parquet
location '/data/qf/travel/ods/ods_travel_pub_common/'
```





##### 景区评论

```
用户：
	user_id
景区ID:
	scenic_id
评分：
	common_score
评分项：
	common_exts
评论时间：
	common_ct
评论内容：
	common_remark
```



数据表

```sql
create external table if not exists ods_travel.ods_travel_scenic_common (
 user_id string COMMENT '用户ID', 
 scenic_id string COMMENT '景区编号',
 common_score double COMMENT '评分',    
 common_exts string COMMENT '评分项(根据业务需求设置目前暂无内容为空)',
 common_remark string COMMENT '评论内容', 
 common_ct bigint COMMENT '评论时间'
) partitioned by (bdp_day string)
stored as parquet
location '/data/qf/travel/ods/ods_travel_scenic_common/'
```





#### <font color="red">车票相关(火车票示例)</font>

##### 车票搜索

```
用户：
	user_id
车次：
	train_number
车型：
	train_style(普通|动车|高铁)
座席：
	train_seat(商务座|一等|二等|软卧|硬卧|硬座|动卧)
出发地：
	train_source
目的地：
	train_target
搜索时间
	search_ct
```



数据表

```sql
create external table if not exists ods_travel.ods_traffic_train_search (
 user_id string COMMENT '用户ID', 
 train_number string COMMENT '车次',
 train_style string COMMENT '车型',    
 train_seat string COMMENT '座席',
 train_source string COMMENT '出发地', 
 train_target string COMMENT '目的地',
 search_ct bigint COMMENT '搜索时间'
) partitioned by (bdp_day string)
stored as parquet
location '/data/qf/travel/ods/ods_traffic_train_search/'
```



##### 车票购买

```
用户：
	user_id
车次：
	train_number
车型：
	train_style(普通|动车|高铁)
座席：
	train_seat(商务座|一等|二等|软卧|硬卧|硬座|动卧)
出发地：
	train_source
目的地：
	train_target
购买价格：
	buy_price
购买时间：
	buy_ct
购买结果：
	buy_result
```



数据表

```sql
create external table if not exists ods_travel.ods_traffic_train_buy (
 user_id string COMMENT '用户ID', 
 train_number string COMMENT '车次',
 train_style string COMMENT '车型',    
 train_seat string COMMENT '座席',
 train_source string COMMENT '出发地', 
 train_target string COMMENT '目的地',
 buy_price string COMMENT '购买价格',
 buy_result string COMMENT '购买结果',
 buy_ct bigint COMMENT '购买时间'
) partitioned by (bdp_day string)
stored as parquet
location '/data/qf/travel/ods/ods_traffic_train_buy/'
```





### 第二节 实时数据

##### 用户日志行为实时日志

```
用于KAFKA分区使用的ID：
	KAFKA_ID: 多字段混合后哈希函数处理得值
会话ID:
	sid
行为类型：
 	action： 'launch启动| interactive交互| page_enter页面曝光(产品页展示)'
事件类型：
  	eventType： 'view浏览（多产品）| slide滑动 (多产品)|click点击(收藏|点赞|分享)'
用户ID：(在一些场景下，平台会为用户构造的唯一编号)
	userID
所属设备号(app端的手机设备号)：
	userDevice
设备类型：
	userDeviceType: '1 android| 2 ios | 9 其他'
操作系统：
	os
手机制造商：
	manufacturer
电信运营商：
	carrier
网络类型：
	networkType
所在区域：
	userRegion
所在区域IP:
	userRegionIP
经度:
	longitude
纬度:
	latitude
停留时长：
	duration
扩展信息
	exts	
事件发生时间：
	ct
	
注释：
热门目的地：(***只有页面浏览日志中出现***)
	hotTarget
```



扩展信息说明

```
请参考本文档中上面 [用户行为日志 -> 行为事件说明]
```





### 第三节 维度数据

#### 地区维度

```
地区编码：
	region_code
地区描述：
	region_code_desc
地区隶属城市：
	region_city
地区城市描述：
	region_city_desc
地区隶属省：
	region_province
地区省描述：
	region_province_desc
```



数据表

```sql
create external table if not exists dim_travel.dim_region (
 region_code string COMMENT '地区编码 如110105  | 130406 ',
 region_code_desc string COMMENT '地区编码 如朝阳区 | 峰峰矿区',
 region_city string COMMENT '地区编码 如1101 北京市朝阳区 | 1304 邯郸',
 region_city_desc string COMMENT '地区编码 如1101 | 1304 邯郸市',
 region_province string COMMENT '地区编码 如11 北京市 | 13 河北省',
 region_province_desc string COMMENT '地区编码 如 北京市 | 河北'
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
location '/data/travel/dim/dim_region/'
```



#### 景区维度

```
景区名称：
	scenic_name
景区地区：
	scenic_area
景区地址：
	scenic_address
景区类型:
	scenic_type 文化古迹、自然风光等
景区级别：
	scenic_level 5A景区
景区特色：
	scenic_tag 世界第八大奇迹

```



数据表

```sql
create external table if not exists dim_travel.dim_scenic (
 scenic_name string COMMENT '景区名称',
 scenic_area string COMMENT '景区地区',
 scenic_address string COMMENT '景区地址',
 scenic_type string COMMENT '景区类型',
 scenic_level string COMMENT '景区级别',
 scenic_tag string COMMENT '景区特色'
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
location '/data/qf/travel/dim/dim_scenic/'
```



#### 店铺维度

```
店铺ID：
	shop_id
店铺名称
	shop_name
店铺地区
	shop_address
店铺供应商：
	supplier_name
```



数据表

```sql
create external table if not exists dim_travel.dim_shop (
 shop_id string COMMENT '店铺ID',
 shop_name string COMMENT '店铺名称',
 shop_address string COMMENT '店铺地址',
 supplier_name string COMMENT '店铺供应商'
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
location '/data/travel/dim/dim_shop/'
```





#### 产品相关维度

```
旅游产品编号：
	product_Id: "598459284410"
旅游产品标题：
	product_title: "VIP15人小团张家界旅游4天3晚森林公园玻璃桥天门山芙蓉镇凤凰"
旅游产品钻级：
	product_level: 1-5星级
行程天数：
	travel_days: 3天
产品类型：	
	travel_type: 自助游,跟团游、私家团、半自助游
游玩路线：
	travel_line_subjects: "[\"张家界\",\"湘西\",\"永定区\",\"武陵源区\",\"慈利县\",\"凤凰县\"]"
住宿信息：	
	travel_lodging_info: "[{\"star\":\"5\",\"grade\":\"豪华型\",\"name\":\"大成山水度假酒店、新天地华天精选酒店、凤天国际酒店 五星级\"},{\"star\":\"5\",\"grade\":\"豪华型\",\"name\":\"新天地华天精选酒店、凤天国际酒店 五星级\"},{\"star\":\"5\",\"grade\":\"豪华型\",\"name\":\"纬地富蓝特酒店、盘龙山庄酒店、传奇凤凰酒店 豪华\"},{\"star\":\"5\",\"grade\":\"豪华型\",\"name\":\"盘龙山庄酒店、传奇凤凰酒店 豪华\"}]"

旅游产品价格：
	product_price: 1999
出发地：
	 departure: "张家界"
目的地：
     des_out: "湖南省"
     des_city: "目的地城市：张家界"
目的地类型：
	 des_sight: 景点地址，若景点地址为-1，则为省份，国外：景点地址，若景点地址为-1，则为国家名称
目的地经济分区：
	 economic_division_out:"中部地区"
是否境内外：
	toursim_tickets_type: 03001:境内旅游、03002:出境旅游（含港澳台）
首次到达：
	first_arriving:"张家界"
产品标签：
	product_tag:特卖汇、优选、温泉体验
产品卖点：
	product_hot:湖南·跟团游」人气产品
		★ 【贴心赠送】678盛夏钜惠【两成人下单立减200元】-赠成人出行礼【山顶小缆车+热景芙蓉镇】
		★ 【五星精选】指定一晚碧桂园【4成人可升级独栋别墅】+一晚凤凰临江5钻客栈【古城内】
		★ 【优选行程】16人超V团-8小时畅玩天门山深度体验湘西之魂-夜宿当地古朴小镇-赏山顶日出
	
```



数据表

```sql
create external table if not exists dim_travel.dim_product (
 product_id string COMMENT '旅游产品编号',
 product_title string COMMENT '旅游产品标题',
 product_level int COMMENT '旅游产品钻级',
 product_type string COMMENT '旅游产品类型(周末游、跟团游、自由行、私家团、游轮)',  
 product_type_desc string COMMENT '旅游产品类型描述',    
 travel_day string COMMENT '旅游行程天数',
 travel_line_subjects string COMMENT '旅游路线',   
 travel_lodging_info string COMMENT '住宿信息',
 product_price string COMMENT '旅游产品价格',   
 departure string COMMENT '出发地',
 departure_code string COMMENT '出发地编码',   
 first_arriving string COMMENT '首次到达城市',
 first_arriving_code string COMMENT '首次到达城市代码',
 des_out string COMMENT '目的地',
 des_city string COMMENT '目的地城市',  
 des_city_desc string COMMENT '目的地代码',
 toursim_tickets_type string COMMENT '是否境内外(03001:境内旅游、03002:出境旅游（含港澳台）)', 
 product_hot string COMMENT '产品卖点',
 shop_id string COMMENT '店铺ID'
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
location '/data/travel/dim/dim_product/'
```





#### 产品扩展信息

```
旅游产品编号：
	product_Id: "598459284410"
产品扩展：
	包含餐饮：
		has_repast
	是否购物：
		has_shopping
	附加景点活动：
		scenic_adds
		附加的景点列表：例如三亚旅游：亚龙湾、千古情景区、南山文化旅游区、南山寺...
	途中交通：
		travel_traffic
		乘坐酒店接驳车前往迪士尼乐园【约15分钟一班】。
		行驶：约2公里/约15分钟
	备注:
		travel_remark
		备注：直飞张家界【自营旗舰全景16人超V团】宿【山顶小镇赏日出+4成人下单升碧桂园独栋别墅+凤凰城内临江5钻客栈】玩【7457米高山索道+365米户外电梯+景区VIP通道】交通自选

```



数据表

```sql
create external table if not exists dim_travel.dim_pub_product_add (
 product_id string COMMENT '旅游产品编号',
 has_repast string COMMENT '包含餐饮',
 has_shopping string COMMENT '是否购物',   
 scenic_adds string COMMENT '附加景点活动',
 travel_traffic string COMMENT '途中交通',   
 travel_remark string COMMENT '备注说明'
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
location '/data/qf/travel/dim/dim_pub_product_add/'
```



#### 酒店相关维度

```
酒店编号：
	pub_id
酒店名称：
	pub_name
酒店星级：
	pub_star
酒店级别：
	pub_grade
酒店级别描述：经济型、中端型、高端型
	pub_grade_desc
是否国内：
	is_national
酒店地区：
	pub_area_code
酒店地址：
	pub_address
```



数据表

```sql
create external table if not exists dim_travel.dim_pub (
 pub_id string COMMENT '酒店编号',
 pub_name string COMMENT '酒店名称',  
 pub_star int COMMENT '酒店星级',
 pub_grade_desc string COMMENT '酒店级别描述',
 pub_grade string COMMENT '酒店级别',
 pub_area_code string COMMENT '酒店地区',
 pub_address string COMMENT '酒店地址', 
 is_national string COMMENT '是否国内'
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
location '/data/qf/travel/dim/dim_pub/'
```



#### 交通维度

```
出行方式：
	traffic_type 飞机、火车、游轮、汽车
车次航班：
	traffic_number
	飞机： 首都航空JD5379
	火车： G181
	游船： 渤海翠珠号
	
所属运营商
	traffic_operator
	飞机： 首都航空
	火车： 中国铁路
	游船： 渤海翠珠号
出发所在城市：
	traffic_area_source 北京
出发位置：
	traffic_source 北京南站
目的地所在城市：
	traffic_area_target 青岛
抵达位置：
	traffic_target 青岛站
乘坐级别：
	traffic_seat_level 商务|一等|二等
价格：
	traffic_price 314
```



数据表

```sql
create external table if not exists dim_travel.dim_pub_traffic (
 traffic_type string COMMENT '出行方式',
 traffic_number string COMMENT '车次航班',
 traffic_operator string COMMENT '所属运营商',   
 traffic_area_source string COMMENT '出发所在城市',
 traffic_source string COMMENT '出发位置',
 traffic_area_target string COMMENT '目的地所在城市',
 traffic_target string COMMENT '抵达位置',
 traffic_seat_level int COMMENT '乘坐级别',  
 traffic_price int COMMENT '价格'
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
location '/data/qf/travel/dim/dim_pub_traffic/'
```



### 第四节 中间数据

#### 产品评价等级

##### 数据schema

```
产品ID:
	product_id
综合评分：
	common_score
评论时间：
	common_ct
好评数:
	good_count
中评数：
	general_count
差评数：
	poor_count
```



##### 数据表

```sql
create external table if not exists mid_travel.mid_travel_product_common (
 product_id string COMMENT '旅游产品编号',
 common_score double COMMENT '综合评分',
 good_count bigint COMMENT '好评数',
 general_count bigint COMMENT '中评数',
 poor_count bigint COMMENT '差评数',
 common_ct bigint COMMENT '评论时间'
) partitioned by (bdp_day string)
stored as parquet
location '/data/qf/travel/mid/mid_travel_product_common/'
```



#### 酒店评价

```
酒店ID:
	pub_id
综合评分：
	common_score
评论时间：
	common_ct
好评数:
	good_count
中评数：
	general_count
差评数：
	poor_count
```



数据表

```sql
create external table if not exists mid_travel.mid_travel_pub_common (
 pub_id string COMMENT '酒店编号',
 common_score double COMMENT '综合评分',
 good_count bigint COMMENT '好评数',
 general_count bigint COMMENT '中评数',
 poor_count bigint COMMENT '差评数',
 common_ct bigint COMMENT '评论时间'
) partitioned by (bdp_day string)
stored as parquet
location '/data/qf/travel/mid/mid_travel_pub_common/'
```



#### 景区评价

```
景区ID:
	scenic_id
综合评分：
	common_score
评论时间：
	common_ct
好评数:
	good_count
中评数：
	general_count
差评数：
	poor_count
```



数据表

```sql
create external table if not exists mid_travel.mid_travel_scenic_common (
 scenic_id string COMMENT '景区编号',
 common_score double COMMENT '综合评分',
 good_count bigint COMMENT '好评数',
 general_count bigint COMMENT '中评数',
 poor_count bigint COMMENT '差评数',
 common_ct bigint COMMENT '评论时间'
) partitioned by (bdp_day string)
stored as parquet
location '/data/qf/travel/mid/mid_travel_scenic_common/'
```



## 第四章 项目开发

### 第一节 开发准备工作

由于pom文件较长，目前仅贴出后续要使用的依赖包，具体情况可参考项目代码

```xml
<!-- mysql -->
<dependency>
	<groupId>mysql</groupId>
	<artifactId>mysql-connector-java</artifactId>
	<version>5.1.44</version>
</dependency>

<!-- kafka-->
<dependency>
	<groupId>org.apache.kafka</groupId>
	<artifactId>kafka_2.11</artifactId>
	<version>1.1.1</version>
</dependency>

<dependency>
	<groupId>org.apache.kafka</groupId>
	<artifactId>kafka-clients</artifactId>
	<version>1.1.1</version>
</dependency>

<!-- flink -->
<dependency>
	<groupId>org.apache.flink</groupId>
	<artifactId>flink-core</artifactId>
	<version>1.9.1</version>
</dependency>

<dependency>
	<groupId>org.apache.flink</groupId>
	<artifactId>flink-scala_2.11</artifactId>
	<version>1.9.1</version>
</dependency>

<dependency>
	<groupId>org.apache.flink</groupId>
	<artifactId>flink-streaming-scala_2.11</artifactId>
	<version>1.9.1</version>
</dependency>

<dependency>
	<groupId>org.apache.flink</groupId>
	<artifactId>flink-clients_2.11</artifactId>
	<version>1.9.1</version>
</dependency>

<dependency>
	<groupId>org.apache.flink</groupId>
	<artifactId>flink-connector-kafka_2.11</artifactId>
	<version>1.9.1</version>
</dependency>

<dependency>
	<groupId>org.apache.flink</groupId>
	<artifactId>flink-table_2.11</artifactId>
	<version>${flink.table.version}</version>
</dependency>

<dependency>
	<groupId>org.apache.flink</groupId>
	<artifactId>flink-jdbc_2.11</artifactId>
	<version>1.9.1</version>
</dependency>
```



### 第二节 实时计算上下文环境构建

#### 背景说明

```
对于使用Flink框架来处理实时场景来说，首先是要构建的是StreamExecutionEnvironment，当然Flink也提供了处理离线场景的对应上下文对象ExecutionEnvironment
基于功能复用的思想我们封装了一些常用的功能形成Flink帮助类：FlinkHelper，下面这段代码提取了构建上下文环境对象的函数。
注释：com.qf.bigdata.realtime.flink.util.help.FlinkHelper
```



#### 构建实时上下文环境对象

```scala
/**
    * 流式环境下的flink上下文构建
    * @param appName
    */
  def createStreamingEnvironment(checkPointInterval :Long) :StreamExecutionEnvironment = {
    var env : StreamExecutionEnvironment = null
    try{
      //构建flink批处理上下文对象
      env = StreamExecutionEnvironment.getExecutionEnvironment

      //设置执行并行度
      env.setParallelism(QRealTimeConstant.DEF_LOCAL_PARALLELISM)

      //开启checkpoint
      env.enableCheckpointing(checkPointInterval, CheckpointingMode.EXACTLY_ONCE)

      //flink服务重启机制
  env.setRestartStrategy(RestartStrategies.fixedDelayRestart(QRealTimeConstant.RESTART_ATTEMPTS,QRealTimeConstant.RESTART_DELAY_BETWEEN_ATTEMPTS))


    }catch{
      case ex:Exception => {
        println(s"FlinkHelper create flink context occur exception：msg=$ex")
        logger.error(ex.getMessage, ex)
      }
    }
    env
  }
```



### 第三节 常用资源连接

#### 背景说明

```
Flink作为计算框架必然会涉及其他资源型框架的读写工作，如存储框架Hadoop、HBase，消息通道Kafka等，当然kafka所能连接的框架还有很多，大部分第三方的连接源称为connector，按照输入或输出位置分为了source和sink，下面我们列举了在实时场景下常用的几种source。
1 kafka消息通道
2 jdbc数据源
```



#### kafka集群配置参数

配置文件：【scr/resource/kafka/flink/kafka-consumer.properties】

```properties
zk.connect=node242:2181,node243:2181,node244:2181/kafka

#broker list
bootstrap.servers=node242:9092,node243:9092,node244:9092

#kafka message 序列化 IntegerDeserializer
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=org.apache.kafka.common.serialization.StringDeserializer

#消费组
group.id=qf_flink_kafka

#request.timeout.ms should be greater than session.timeout.ms and fetch.max.wait.ms
request.timeout.ms=60000

#consumer-kafka(broker controller)( <= 1/3 * session.timeout.ms)
heartbeat.interval.ms=15000

#consumer group
#broker group.min.session.timeout.ms(6000) < ? < group.max.session.timeout.ms(30,0000)
session.timeout.ms=40000

#consumer
fetch.max.wait.ms=5000

##fetch min
fetch.min.bytes=0

#fetch.max(message.max.bytes=1000012 10m, producer max.request.size=1048576 10m)
fetch.max.bytes=1000012

# (broker message.max.bytes=1000012 10m )
max.partition.fetch.bytes=1000012

#offset [latest, earliest, none]
auto.offset.reset=latest

#kafka commit
enable.auto.commit=false
auto.commit.interval.ms= 2000

#consumer
#max.poll.interval.ms=20000

#consumer
#max.poll.records=500

#compression type=none, gzip, snappy, lz4, producer
#compression.type=snappy

#consumer producer receive.buffer.bytes=32768
#receive.buffer.bytes=65536

#consumer
#send.buffer.bytes=131072

#broker
#metadata.max.age.ms=300000

#consumer
#reconnect.backoff.ms=50
```



#### Kafka-Flink消费

```scala
/**
    * flink读取kafka数据
    * @param env
    * @param topic
    * @param properties
    * @return
    */
  def createKafkaConsumer(env:StreamExecutionEnvironment, topic:String, properties:Properties) :FlinkKafkaConsumer[String] = {
    //kafka数据序列化
    val schema = new SimpleStringSchema()

    //创建消费者和消费策略
    val kafkaConsumer : FlinkKafkaConsumer[String] = new FlinkKafkaConsumer[String](topic, schema, properties)
    kafkaConsumer
  }
```



#### mysql配置参数

配置文件：【scr/resource/jdbc.properties】

```properties
jdbc.driver=com.mysql.jdbc.Driver
jdbc.user=root
jdbc.password=12345678
jdbc.url=jdbc:mysql://10.0.88.242:3306/travel?serverTimezone=UTC&characterEncoding=utf-8
```



#### JDBC-Flink读取

```scala
/**
    * 创建jdbc数据源输入格式
    * @param driver
    * @param username
    * @param passwd
    * @return
    */
  def createJDBCInputFormat(driver:String, url:String, username:String, passwd:String,
                            query:String, fieldTypes: Seq[TypeInformation[_]]): JDBCInputFormat = {

    //记录列信息
    val rowTypeInfo = new RowTypeInfo(fieldTypes:_*)

    //数据源提取
    val jdbcInputFormat :JDBCInputFormat = JDBCInputFormat.buildJDBCInputFormat()
      .setDrivername(driver)
      .setDBUrl(url)
      .setUsername(username)
      .setPassword(passwd)
      .setRowTypeInfo(rowTypeInfo)
      .setQuery(query)
      .finish();

    jdbcInputFormat
  }


  /**
    * 维度数据加载
    * @param env
    * @param sql
    * @param fieldTypes
    * @return
    */
  def createOffLineDataStream(env: StreamExecutionEnvironment, sql:String, fieldTypes: Seq[TypeInformation[_]]):DataStream[Row] = {
    //JDBC属性
    val mysqlDBProperties :Properties = PropertyUtil.readProperties(QRealTimeConstant.MYSQL_CONFIG_URL)
    val jdbcInputFormat : JDBCInputFormat= FlinkHelper.createJDBCInputFormat(mysqlDBProperties, sql, fieldTypes)
    val jdbcDataStream :DataStream[Row] = env.createInput(jdbcInputFormat)
    jdbcDataStream
  }



  /**
    * 创建jdbc数据源输入格式
    * @param properties
    * @param query
    * @param fieldTypes
    * @return
    */
  def createJDBCInputFormat(properties:Properties, query:String, fieldTypes: Seq[TypeInformation[_]]): JDBCInputFormat = {
    val driver :String = properties.getProperty(TravelConstant.FLINK_JDBC_DRIVER_MYSQL_KEY)
    val url :String = properties.getProperty(TravelConstant.FLINK_JDBC_URL_KEY)
    val user:String = properties.getProperty(TravelConstant.FLINK_JDBC_USERNAME_KEY)
    val passwd:String = properties.getProperty(TravelConstant.FLINK_JDBC_PASSWD_KEY)

    val jdbcInputFormat : JDBCInputFormat = createJDBCInputFormat(driver, url, user, passwd,
      query, fieldTypes)
    jdbcInputFormat
  }
```





#### 项目配置常量

背景说明

```
项目开发过程中涉及到的配置参数、参数数值尽量用类常量设置，而不要使用硬编码方式，下面示例展示了部分主要的配置参数(摘自QRealTimeConstant)，全部参数请参考项目代码
注释：com.qf.bigdata.realtime.flink.constant.QRealTimeConstant
```

```scala
//常数1
val COMMON_NUMBER_ZERO : Long = Long.box(0l)
val COMMON_NUMBER_ZERO_INT : Int = Int.box(0)
val COMMON_NUMBER_ONE : Long = Long.box(1l)
val COMMON_AGG_ZERO : Double = Double.box(0.0d)
val COMMON_MAX_COUNT : Long = Long.box(100)


//kafka消费者配置文件
val KAFKA_CONSUMER_CONFIG_URL = "kafka/flink/kafka-consumer.properties"
//kafka生产者配置文件
val KAFKA_PRODUCER_CONFIG_URL = "kafka/flink/kafka-producer.properties"


//mysql属性文件
val MYSQL_CONFIG_URL = "jdbc.properties"


//flink最大乱序时间
val FLINK_WATERMARK_MAXOUTOFORDERNESS = 5 * 1000l

//flink水位间隔时间
val FLINK_WATERMARK_INTERVAL = 5 * 1000l

//flink窗口大小
val FLINK_WINDOW_SIZE :Long = 5 * 1
val FLINK_WINDOW_MAX_SIZE :Long = 60 * 1

//flink滑动窗口大小
val FLINK_SLIDE_WINDOW_SIZE :Long= 10l
val FLINK_SLIDE_INTERVAL_SIZE :Long= 5l

//flink检查点间隔
val FLINK_CHECKPOINT_INTERVAL :Long = 20 * 1000l

//flink延时设置
val FLINK_ALLOWED_LATENESS :Long = 10l


//本地模型下的默认并行度(cpu core)
val DEF_LOCAL_PARALLELISM  = Runtime.getRuntime.availableProcessors

//flink服务重启策略相关参数
val RESTART_ATTEMPTS :Int = 5
val RESTART_DELAY_BETWEEN_ATTEMPTS :Long = 1000L * 10L

//广播变量名称
val BC_ACTIONS = "bc_actions"
val BC_PRODUCT = "bc_product"
val BC_PRODUCT_ASYNC = "bc_product_sync"

//外部传参名称
val PARAMS_KEYS_APPNAME = "appname"
val PARAMS_KEYS_GROUPID = "gruopid"
val PARAMS_KEYS_TOPIC_FROM = "from_topic"
val PARAMS_KEYS_TOPIC_TO = "to_topic"
val PARAMS_KEYS_INDEX_NAME = "index"


//kafka参数
val TOPIC_LOG_ODS = "topic_log_ods"

val TOPIC_LOG_ACTION_VIEW = "topic_log_action_view"
val TOPIC_LOG_ACTION_VIEW_STATIS = "topic_log_action_view_statis"

val TOPIC_LOG_ACTION_CLICK = "topic_log_action_click"
val TOPIC_LOG_ACTION_LAUNCH = "topic_log_action_launch"
val TOPIC_LOG_ACTION_PAGE_ENTER = "topic_log_action_page_enter"
val TOPIC_LOG_ACTION_VIEWLIST = "topic_log_action_viewlist"

val TOPIC_LOG_ACTION_LAUNCH_WARN = "topic_log_action_launch_warn"

val TOPIC_ORDER_ODS = "topic_orders_ods"
val TOPIC_ORDER_DW_WIDE = "topic_orders_dw_wide"
val TOPIC_ORDER_DM = "topic_orders_dm"
val TOPIC_ORDER_DM_STATIS = "topic_orders_dm_statis"

val TOPIC_ORDER_MID = "topic_orders_mid"

//测流输出
val OUTPUT_TAG_LOG_PAGEVIEW = "output_tag_pageview_lowDuration"

//===es索引 旅游产品订单=====================================

val ES_INDEX_NAME_ORDER_DETAIL = "travel_order_detail"
val ES_INDEX_NAME_ORDER_AGG = "travel_order_agg"
val ES_INDEX_NAME_ORDER_WIN_STATIS = "travel_order_win_statis"
val ES_INDEX_NAME_ORDER_CUSTOMER_STATIS = "travel_order_customer_statis"

val ES_INDEX_NAME_ORDER_WIDE_DETAIL = "travel_order_wide"
val ES_INDEX_NAME_ORDER_WIDE_AGG = "travel_order_wide_agg"

//===es索引 用户日志=====================================
//启动日志聚合数据对应es索引名称
val ES_INDEX_NAME_LOG_LAUNCH_AGG = "travel_log_launch_agg"

//页面浏览日志明细数据对应es索引名称
val ES_INDEX_NAME_LOG_VIEW = "travel_log_pageview"
val ES_INDEX_NAME_LOG_VIEW_LOW = "travel_log_pageview_low"

//用户日志点击行为明细数据对应es索引名称
val ES_INDEX_NAME_LOG_CLICK = "travel_log_click"
val ES_INDEX_NAME_LOG_CLICK_STATIS = "travel_log_click_statis"

//ES集群配置文件
val ES_CONFIG_PATH = "es/es-config.json"
val KEY_ES_ID = "id"

//ES同记录写入并发重试次数
val ES_RETRY_NUMBER = 15

//ES索引中的时间列
val esCt = "es_ct"
val esUt = "es_ut"

val ES_PV = "view_count"
val ES_MAX = "max_metric"
val ES_MIN = "min_metric"
val ES_ORDERS = "orders"


val DYNC_DBCONN_TIMEOUT = 1
val DYNC_DBCONN_CAPACITY = 3


//时间格式
val FORMATTER_YYYYMMDD: String = "yyyyMMdd"
val FORMATTER_YYYYMMDD_MID: String = "yyyy-MM-dd"
val FORMATTER_YYYYMMDDHH: String = "yyyyMMddHH"
val FORMATTER_YYYYMMDDHHMMSS: String = "yyyyMMddHHmmss"

//实时采集参数
val RM_REC_ROLLOVER_INTERVAL :Long = 15L
val RM_REC_INACTIVITY_INTERVAL :Long = 5L
val RM_REC_MAXSIZE :Long = 128L
val RM_REC_BUCKET_CHECK_INTERVAL :Long = 5L

val KEY_RM_REC_OUTPUT :String = "output"
val KEY_RM_REC_ROLLOVER_INTERVAL :String = "rollover_interval"
val KEY_RM_REC_INACTIVITY_INTERVAL :String = "inactivity_interval"
val KEY_RM_REC_MAXSIZE :String = "max_size"
val KEY_RM_REC_BUCKET_CHECK_INTERVAL :String = "bucket_check_interval"

val KEY_RM_TIME_RANGE :String = "time_range"
val KEY_RM_LAUNCH_COUNT :String = "launch_count"

```



### 第四节 数据通道

#### 背景说明

```
目前实时场景的数据来源一般是取自消息队列(如kafka)，下面我们看看如何使用Flink来进行kafka数据的读取工作。
我们以用户行为日志中的点击行为为示例进行说明，下例为用户点击行为明细处理类UserLogsClickHandler中的局部片段，具体完整代码请参考项目相关代码。
注释：com.qf.bigdata.realtime.flink.streaming.etl.ods.UserLogsClickHandler
```



#### 点击行为日志数据处理

##### 读取消息队列数据

(1) 创建Flink实时上下文环境对象(【构建实时上下文环境对象】上列已有不再重复)

```scala
//1 flink环境初始化使用事件时间做处理参考
      val env: StreamExecutionEnvironment = FlinkHelper.createStreamingEnvironment(QRealTimeConstant.FLINK_CHECKPOINT_INTERVAL)
      env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
      env.getConfig.setAutoWatermarkInterval(QRealTimeConstant.FLINK_WATERMARK_INTERVAL)
```



(2) 连接kafka服务集群

```
Flink读取kafka采用的是connector方式
1 加载相关jar包(maven)，参考【开发准备工作】
2 配置kafka集群相关参数及消费方式
3 kafka数据反序列化处理
4 调用相关API进行操作
```



##### 配置kafka集群相关参数及消费方式

###### kafka集群参数

注释：请参考上面【kafka集群配置参数】



###### kafka消费方式

```scala
//2 kafka流式数据源
val consumerProperties :Properties = PropertyUtil.readProperties(QRealTimeConstant.KAFKA_CONSUMER_CONFIG_URL)

//创建消费者和消费策略
val schema:KafkaDeserializationSchema[UserLogData] = new UserLogsKSchema(fromTopic)

val kafkaConsumer : FlinkKafkaConsumer[UserLogData] = new FlinkKafkaConsumer[UserLogData](fromTopic, schema, consumerProperties)
      kafkaConsumer.setStartFromLatest()


//消费方式：最早消息、最近消息、偏移量定位
kafkaConsumer.setStartFromLatest()
```



###### kafka数据反序列化处理

用户行为日志

```scala
/**
* kafka数据反序列化处理
* 这样可以直接将消息中的json格式数据转换为对应case class对象
*/
class UserLogsKSchema(topic:String) extends KafkaSerializationSchema[UserLogData] with KafkaDeserializationSchema[UserLogData] {

  val gson : Gson = new Gson()

  /**
    * 反序列化
    * @param message
    * @return
    */
  override def deserialize(record: ConsumerRecord[Array[Byte], Array[Byte]]): UserLogData = {
    val key = record.key()
    val value = record.value()
    val log :UserLogData = gson.fromJson(new String(value), classOf[UserLogData])
    log
  }

  /**
    * 序列化
    * @param element
    * @return
    */
  override def serialize(element: UserLogData, timestamp: lang.Long): ProducerRecord[Array[Byte], Array[Byte]] = {
    val key = element.sid
    val value = JsonUtil.gObject2Json(element)
    new ProducerRecord[Array[Byte], Array[Byte]](topic, key.getBytes, value.getBytes)
  }

  override def isEndOfStream(nextElement: UserLogData): Boolean = {
    return false
  }

  override def getProducedType: TypeInformation[UserLogData] = {
    return TypeInformation.of(classOf[UserLogData])
  }
```



###### 用户行为日志数据对象

```scala
/**
    * 用户行为日志原始数据
    */
case class UserLogData(sid:String, userDevice:String, userDeviceType:String, os:String,
                       userID:String,userRegion:String, userRegionIP:String,                                    lonitude:String, latitude:String,manufacturer:String,                                    carrier:String, networkType:String, duration:String, exts:String,
                       action:String, eventType:String, ct:Long)
```



#####  构建实时数据流

```
Flink对数据输入与输出分别称为：source 和 sink
1 通过设置输入数据source(FlinkKafkaConsumer对象)
2 设置并行度slot数量
```



```scala
//形成实时数据流
val dStream :DataStream[UserLogData] = env.addSource(kafkaConsumer).setParallelism(QRealTimeConstant.DEF_LOCAL_PARALLELISM)
```





### 第五节 实时数据ETL

#### 背景说明

```
实时场景下，原始数据可能存在不规范、较脏的情况，尤其是在高并发或需要处理的业务逻辑较复杂的情况下，对于实时场景的数据计算处理性能产生一定影响，这样需要我们对各类实时指标进行多阶段分步处理，比如第一步为数据规范处理(ETL),第二步为业务指标计算。经过第一步的数据清理工作后再发送到数据通道(kafka)中做消费计算，这样提高了实时处理性能同时数据复用得到了保障，同时对于有实时明细数据查询或动态聚合需求的情况可以结合其他技术进行实现(如druid可以对实时数据进行摄取提供对使用者的各种计算方式的支持)
最后强调一点：多步骤处理实时场景问题时是根据数据并发程度、计算复杂性、平台计算时效性等综合指标来确定的，在实际工作中要根据实际情况来进行处理，不必照搬这种设计方案！！！
```



#### 用户行为日志

##### 用户点击行为示例数据

```json
{
    "os": "2",
    "lonitude": "101.27417",
    "userRegion": "532823",
    "latitude": "21.45517",
    "eventType": "02",
    "userID": "32444",
    "sid": "20200103153500rgnuk",
    "manufacturer": "01",
    "duration": "0",
    "ct": "1578036900000",
    "carrier": "1",
    "userRegionIP": "67.77.242.139",
    "userDeviceType": "9",
    "KAFKA_ID": "74fk16e7bh",
    "action": "05",
    "userDevice": "94168",
    "networkType": "0",
    "exts": "{
		"eventTargetType":"101",
		"targetID":"P46"
	}"
}
```



###### 背景说明

```
正如上例所示，我们在进行点击日志统计时需要提取扩展字段(exts)中对应的数据信息，这些可能要作为统计维度参与业务统计，所以需要先进行实时数据ETL工作,按照之前的相关代码我们已经获取了kafka的数据并通过Flink读取形成数据流，如下列所示，具体代码参考UserLogsClickHandler
注释：com.qf.bigdata.realtime.flink.streaming.etl.ods.UserLogsClickHandler
```



###### kafka数据反序列化

```
用户点击行为日志的kafka数据反序列化参考 第四节【kafka数据反序列化处理】
```



###### 数据过滤

```scala
//交互点击行为
val clickDStream :DataStream[UserLogClickData] = dStream.filter(
        (log : UserLogData) => {
          log.action.equalsIgnoreCase(ActionEnum.INTERACTIVE.getCode) && log.eventType.equalsIgnoreCase(EventEnum.CLICK.getCode)
        }
      ).map(new UserLogClickDataMapFun())
```



###### 数据转换

注释：转换函数UserLogClickDataMapFun

```scala
/**
    * 用户日志点击数据实时数据转换
    */
  class UserLogClickDataMapFun extends MapFunction[UserLogData,UserLogClickData]{

    override def map(value: UserLogData): UserLogClickData = {
      val sid :String = value.sid
      val userDevice:String = value.userDevice
      val userDeviceType:String = value.userDeviceType
      val os:String = value.os
      val userID :String = value.userID
      val userRegion :String = value.userRegion
      val userRegionIP:String = value.userRegionIP
      val lonitude:String = value.lonitude
      val latitude:String = value.latitude
      val manufacturer:String = value.manufacturer
      val carrier:String = value.carrier
      val networkType:String = value.networkType
      val action:String = value.action
      val eventType:String = value.eventType
      val ct:Long = value.ct
      val exts :String = value.exts
      var targetID :String = ""
      var eventTargetType :String = ""
      if(StringUtils.isNotEmpty(exts)){
        val extMap :mutable.Map[String,AnyRef] = JsonUtil.gObject2Map(exts)
        targetID = extMap.getOrElse(QRealTimeConstant.KEY_TARGET_ID, "").toString
        eventTargetType = extMap.getOrElse(QRealTimeConstant.KEY_EVENT_TARGET_TYPE, "").toString
      }

      UserLogClickData(sid, userDevice, userDeviceType, os,
        userID,userRegion, userRegionIP, lonitude, latitude,
        manufacturer, carrier, networkType,
        action, eventType, ct, targetID, eventTargetType)

    }
  }

```



###### 原始数据

```scala
/**
    * 用户行为日志原始数据
    */
  case class UserLogData(sid:String, userDevice:String, userDeviceType:String, os:String,
                          userID:String,userRegion:String, userRegionIP:String, lonitude:String, latitude:String,
                          manufacturer:String, carrier:String, networkType:String, duration:String, exts:String,
                          action:String, eventType:String, ct:Long)
```



###### ETL后的规范数据

```scala
/**
    *用户行为日志点击操作数据
    */
case class UserLogClickData(sid:String, userDevice:String, userDeviceType:String, os:String,userID:String,userRegion:String, userRegionIP:String, lonitude:String, latitude:String,manufacturer:String, carrier:String, networkType:String,action:String, eventType:String, ct:Long, targetID:String, eventTargetType:String)

```



##### 用户产品列表浏览示例数据

```json
{
    "os": "1",
    "lonitude": "105.72017",
    "userRegion": "520381",
    "latitude": "28.45833",
    "eventType": "01",
    "userID": "59229",
    "sid": "20200103153500rkfxn",
    "manufacturer": "09",
    "duration": "54",
    "ct": "1578036900000",
    "carrier": "1",
    "userRegionIP": "64.234.5.53",
    "userDeviceType": "2",
    "KAFKA_ID": "ne31j8m79k",
    "action": "05",
    "userDevice": "25941",
    "hotTarget": "530829", 热门目的地
    "networkType": "3",
    "exts": "{
			"travelSendTime":"202002",
			"travelTime":"9",
			"productLevel":"4",
			"targetIDS":"["P40","P46","P28","P62"]",
			"travelSend":"520381",
			"productType":"01"
	}"
}
```



###### 背景说明

```
请仔细观察【用户点击行为示例数据】和【用户产品列表浏览示例数据】，你会发现除了数据schema有些不同外最主要的是扩展信息exts中的【targetIDS】字段为json数组形式，结合业务含义，表达的是一个用户通过查询搜索获得的产品列表或用户在上下滑动手机进行类似翻页浏览产品页信息，但如果我们有【热门产品】统计、排名等需求时首先要将这些列表进行拆分，从软件功能上来讲称为"1拆多"(flatMap)，所以在后续做指标统计之前第一步先做好数据的ETL工作，具体如下列所示，具体代码参考UserLogsViewListHandler
注释：com.qf.bigdata.realtime.flink.streaming.etl.ods.UserLogsViewListHandler
```



###### kafka数据反序列化

```scala
//创建消费者和消费策略
val schema:KafkaDeserializationSchema[UserLogViewListData] = new UserLogsViewListKSchema(fromTopic)
    
val kafkaConsumer : FlinkKafkaConsumer[UserLogViewListData] = new FlinkKafkaConsumer[UserLogViewListData](fromTopic, schema, consumerProperties)
    
kafkaConsumer.setStartFromLatest()
```



注释：具体代码参考 com.qf.bigdata.realtime.flink.schema.UserLogsViewListKSchema

```scala
/**
  * 行为日志产品列表浏览数据(原始)kafka序列化
  */
class UserLogsViewListKSchema(topic:String) extends KafkaSerializationSchema[UserLogViewListData] with KafkaDeserializationSchema[UserLogViewListData] {

  val gson : Gson = new Gson()


  /**
    * 反序列化
    * @param message
    * @return
    */
  override def deserialize(record: ConsumerRecord[Array[Byte], Array[Byte]]): UserLogViewListData = {
    val key = record.key()
    val value = record.value()
    val log :UserLogViewListData = gson.fromJson(new String(value), classOf[UserLogViewListData])
    log
  }

  /**
    * 序列化
    * @param element
    * @return
    */
  override def serialize(element: UserLogViewListData, timestamp: lang.Long): ProducerRecord[Array[Byte], Array[Byte]] = {
    val sid = element.sid
    val userDevice = element.userDevice
    val userID = element.userID
    val tmp = sid + userDevice+ userID
    val key = CommonUtil.getMD5AsHex(tmp.getBytes)

    val value = JsonUtil.gObject2Json(element)
    new ProducerRecord[Array[Byte], Array[Byte]](topic, key.getBytes, value.getBytes)
  }

  override def isEndOfStream(nextElement: UserLogViewListData): Boolean = {
    return false
  }

  override def getProducedType: TypeInformation[UserLogViewListData] = {
    return TypeInformation.of(classOf[UserLogViewListData])
  }


}
```



###### 列表数据处理

```scala
//3 实时流数据集合操作
val dStream :DataStream[UserLogViewListData] = env.addSource(kafkaConsumer).setParallelism(QRealTimeConstant.DEF_LOCAL_PARALLELISM)

//产品列表浏览
val viewListFactDStream :DataStream[UserLogViewListFactData] = dStream.filter(
(log : UserLogViewListData) => {
	log.action.equalsIgnoreCase(ActionEnum.INTERACTIVE.getCode) && 			EventEnum.getViewListEvents.contains(log.eventType)
}
).flatMap(new UserLogsViewListFlatMapFun())
```



###### 列表拆分处理

```scala
/**
    * 用户行为原始数据ETL
    * 数据扁平化处理：浏览多产品记录拉平
    */
  class UserLogsViewListFlatMapFun extends FlatMapFunction[UserLogViewListData,UserLogViewListFactData]{

    override def flatMap(value: UserLogViewListData, values: Collector[UserLogViewListFactData]): Unit = {

      val sid :String = value.sid
      val userDevice:String = value.userDevice
      val userDeviceType:String = value.userDeviceType
      val os:String = value.os
      val userID :String = value.userID
      val userRegion :String = value.userRegion
      val userRegionIP:String = value.userRegionIP
      val lonitude:String = value.lonitude
      val latitude:String = value.latitude
      val manufacturer:String = value.manufacturer
      val carrier:String = value.carrier
      val networkType:String = value.networkType
      val duration :String = value.duration
      val action:String = value.action
      val eventType:String = value.eventType
      val ct:Long = value.ct
      val hotTarget:String = value.hotTarget
      val exts :String = value.exts

      if(StringUtils.isNotEmpty(exts)){
        val extMap :mutable.Map[String,AnyRef] = JsonUtil.gObject2Map(exts)
        val travelSendTime = extMap.getOrElse(QRealTimeConstant.KEY_TRAVEL_SENDTIME, "").toString
        val travelSend = extMap.getOrElse(QRealTimeConstant.KEY_TRAVEL_SEND, "").toString
        val travelTime = extMap.getOrElse(QRealTimeConstant.KEY_TRAVEL_TIME, "").toString
        val productLevel = extMap.getOrElse(QRealTimeConstant.KEY_PRODUCT_LEVEL, "").toString
        val productType = extMap.getOrElse(QRealTimeConstant.KEY_PRODUCT_TYPE, "").toString
        val targetIDSJson = extMap.getOrElse(QRealTimeConstant.KEY_TARGET_IDS, "").toString

        //列表拆分
        val targetIDS :util.List[String] = JsonUtil.gJson2List(targetIDSJson)
        for(targetID <- targetIDS){
          val data = UserLogViewListFactData(sid, userDevice, userDeviceType, os,
            userID,userRegion, userRegionIP, lonitude, latitude,
            manufacturer, carrier, networkType, duration,
            action, eventType, ct,
            targetID, hotTarget, travelSend, travelSendTime,
            travelTime, productLevel, productType)

          values.collect(data)
        }
      }
    }
  }
```



###### 原始数据

```scala
/**
    * 用户行为日志产品列表浏览数据
    */
  case class UserLogViewListData(sid:String, userDevice:String, userDeviceType:String, ·								os:String,userID:String,userRegion:String, 					 							userRegionIP:String, lonitude:String, latitude:String,
                                manufacturer:String, carrier:String, networkType:String, 								 duration:String, exts:String,action:String, 											eventType:String, ct:Long,hotTarget:String)
```



###### ETL后的规范数据

```scala
/**
    *用户行为日志产品列表浏览数据
    */
case class UserLogViewListFactData(sid:String, userDevice:String,userDeviceType:String, 					os:String,userID:String,userRegion:String, userRegionIP:String, 					  lonitude:String, latitude:String,manufacturer:String, carrier:String, 				  networkType:String, duration:String,action:String, eventType:String, 			          ct:Long,targetID:String,hotTarget:String,travelSend:String,
                  travelSendTime:String,travelTime:String, productLevel:String,                             productType:String)
```



### 第六节 实时宽表数据构成

#### 背景说明

```
如果我们做过离线数仓会知道有事实层、维表层、集市层等，集市层或中间层的统计数据、明细数据往往会是宽表数据或基于宽表数据聚合而来，在实时数仓中也是类似，根据需求我们会将消息通道的数据作为事实数据，把维表数据通过广播等方式加载到任务执行节点(taskManager)上进行宽表数据合成，进而后续可以完成不同的统计需求，但这里与多维计算模型不同(keylin处理多维计算模型的框架)，仅仅是在一定范围内的分组聚合，如你有多维计算的需求请直接使用kylin即可(kylin对离线和实时2种场景都支持)，所以下面我们聊聊宽表数据的构成过程，下面代码为主要代码，具体代码请参考项目, 下面示例是旅游产品订单业务。
注释：
1 广播方式 com.qf.bigdata.realtime.flink.streaming.etl.dw.orders.OrdersWideDetail2ESHandler
2 异步IO方式 com.qf.bigdata.realtime.flink.streaming.etl.dw.orders.OrdersWideAsyncHander
```



#### 业务背景

旅游产品订单 

​		参考 第三章 第一节 【旅游产品订单】

离线数据表

```sql
create external table if not exists ods_travel.ods_travel_orders (
 user_id string COMMENT '用户ID', 
 user_mobile string COMMENT '用户手机号',
 product_id string COMMENT '旅游产品编号',
 product_traffic string COMMENT '旅游产品交通资源',
 product_traffic_grade string COMMENT '旅游产品交通:座席', 
 product_traffic_type string COMMENT '旅游产品交通:行程种类',   
 product_pub string COMMENT '旅游产品住宿资源', 
 user_region string COMMENT '用户所在区域',  
 travel_member_adult int COMMENT '人员构成_成人人数',
 travel_member_yonger int COMMENT '人员构成_儿童人数',
 travel_member_baby int COMMENT '人员构成_婴儿人数', 
 product_price double COMMENT '产品价格', 
 has_activity double COMMENT '活动特价',   
 product_fee double COMMENT '产品费用', 
 order_ct bigint COMMENT '日志时间'
) partitioned by (bdp_day string)
stored as parquet
location '/data/qf/travel/ods/ods_travel_orders/'
```



#### 宽表构造

```
从上面的【旅游产品订单】中可以看出与其相关的维表有【地域维度表】、【旅游产品维度表】、可能还有【酒店维度表】(具体看是否包含在旅游产品中)，在此我们先以【旅游产品维度表】示例看看如何进行宽表构造。
强调一点维表数据量不能很大(当然维表数据量级较大的话会放在hbase之中)！！！
```



##### 广播方式

注释：具体代码参考com.qf.bigdata.realtime.flink.streaming.etl.dw.orders.OrdersWideDetail2ESHandler



###### 维度数据提取

```
对于mysql维表的读取工作，本例是基于Flink-JDBC包来完成的
1 创建读取的mysql数据源(表)的字段类型列表，List[TypeInformation[_]]
2 构造JDBCInputFormat，随后形成[Row]元素形式的数据流DataStream
3 转换为维表对象ProductDimDO
```



查询使用的产品维度信息

下列语句来自QRealTimeConstant

```scala
val SQL_PRODUCT = s"""
        select
        |product_id,
        |product_level,
        |product_type,
        |departure_code,
        |des_city_code,
        |toursim_tickets_type
        from ${MYDQL_DIM_PRODUCT}
      """.stripMargin
```



mysql数据表字段类型列表

对照上面的sql语句构造了所选字段类型信息

```scala
/**
  * 维表数据表结构信息
  */
object QRealTimeDimTypeInformations {
  //旅游产品表涉及列类型(所选列集合)
  def getProductDimFieldTypeInfos() : List[TypeInformation[_]] = {
    var colTypeInfos :List[TypeInformation[_]] = List[TypeInformation[_]]()
    colTypeInfos = colTypeInfos.:+(BasicTypeInfo.STRING_TYPE_INFO)
    colTypeInfos = colTypeInfos.:+(BasicTypeInfo.INT_TYPE_INFO)
    colTypeInfos = colTypeInfos.:+(BasicTypeInfo.STRING_TYPE_INFO)
    colTypeInfos = colTypeInfos.:+(BasicTypeInfo.STRING_TYPE_INFO)
    colTypeInfos = colTypeInfos.:+(BasicTypeInfo.STRING_TYPE_INFO)
    colTypeInfos = colTypeInfos.:+(BasicTypeInfo.STRING_TYPE_INFO)
    colTypeInfos
  }
}
```



构造JDBCInputFormat

```scala
/**
    * 维度数据加载
    * @param env
    * @param sql
    * @param fieldTypes
    * @return
    */
  def createOffLineDataStream(env: StreamExecutionEnvironment, sql:String, fieldTypes: Seq[TypeInformation[_]]):DataStream[Row] = {
    //JDBC属性
    val mysqlDBProperties :Properties = PropertyUtil.readProperties(QRealTimeConstant.MYSQL_CONFIG_URL)
    val jdbcInputFormat : JDBCInputFormat= FlinkHelper.createJDBCInputFormat(mysqlDBProperties, sql, fieldTypes)
    val jdbcDataStream :DataStream[Row] = env.createInput(jdbcInputFormat)
    jdbcDataStream
  }
```



维度数据提取转换

```scala
/**
      * 2 离线维度数据提取
      *   旅游产品维度数据
      */
    val productDimFieldTypes :List[TypeInformation[_]] = QRealTimeDimTypeInformations.getProductDimFieldTypeInfos()
    //mysql查询sql
    val sql = QRealTimeConstant.SQL_PRODUCT
    val productDS :DataStream[ProductDimDO] = FlinkHelper.createOffLineDataStream(env, sql, productDimFieldTypes).map(
      (row: Row) => {
        val productID = row.getField(0).toString
        val productLevel = row.getField(1).toString.toInt
        val productType = row.getField(2).toString
        val depCode = row.getField(3).toString
        val desCode = row.getField(4).toString
        val toursimType = row.getField(5).toString
        new ProductDimDO(productID, productLevel, productType, depCode, desCode, toursimType)
      }
    )
```



维表数据形成广播流

```scala
//状态描述对象
val productMSDesc = new MapStateDescriptor[String, ProductDimDO](QRealTimeConstant.BC_PRODUCT, createTypeInformation[String], createTypeInformation[ProductDimDO])
 
//产品维表广播流
val dimProductBCStream :BroadcastStream[ProductDimDO] = productDS.broadcast(productMSDesc)
```





###### 订单实时数据

```
如同在【kafka-Flink消费】中类似，通过对订单业务所对应的kafka topic读取并进行转换形成了订单明细对象OrderDetailData，同时基于事件时间进行窗口数据划分并设置了水位，最终形成订单数据流。
注释：下列代码来自于com.qf.bigdata.realtime.flink.streaming.etl.dw.orders.OrdersWideDetail2ESHandler
```



```scala
/**
 * 4 订单数据
 *   原始明细数据转换操作
 */
val dStream :DataStream[String] = env.addSource(kafkaConsumer).setParallelism(QRealTimeConstant.DEF_LOCAL_PARALLELISM)

val orderDetailDStream :DataStream[OrderDetailData] = dStream.map(new OrderDetailDataMapFun())


/**
 * 5 设置事件时间提取器及水位计算
 *   固定范围的水位指定(注意时间单位)
*/
val ordersPeriodicAssigner = new OrdersPeriodicAssigner(QRealTimeConstant.FLINK_WATERMARK_MAXOUTOFORDERNESS)
orderDetailDStream.assignTimestampsAndWatermarks(ordersPeriodicAssigner)

```



###### 广播构造宽表

```scala
/**
 * 旅游产品宽表数据
 * 1 产品维度
 * 2 订单数据
 */
val orderWideDStream :DataStream[OrderWideData] = orderDetailDStream.connect(dimProductBCStream)
      .process(new OrderWideBCFunction(QRealTimeConstant.BC_PRODUCT))
```



构造合成过程

```scala
/**
    * 订单数据广播处理
    * 订单开窗宽表数据
    */
  class OrderWideBCFunction(bcName:String) extends BroadcastProcessFunction[OrderDetailData, ProductDimDO, OrderWideData]{

    val productMSDesc = new MapStateDescriptor[String,ProductDimDO](bcName, createTypeInformation[String], createTypeInformation[ProductDimDO])

    //维度数据收集器
    var products :Seq[ProductDimDO] = List[ProductDimDO]()


    override def open(parameters: Configuration): Unit = {
      super.open(parameters)
    }

    //流式数据处理
    override def processElement(value: OrderDetailData, ctx: BroadcastProcessFunction[OrderDetailData, ProductDimDO, OrderWideData]#ReadOnlyContext, out: Collector[OrderWideData]): Unit = {

      val productBState :ReadOnlyBroadcastState[String,ProductDimDO] = ctx.getBroadcastState(productMSDesc);

      val orderProductID :String = value.productID
      if(productBState.contains(orderProductID)){
        val productDimDO :ProductDimDO = productBState.get(orderProductID)

        val productLevel = productDimDO.productLevel
        val productType = productDimDO.productType
        val toursimType = productDimDO.toursimType
        val depCode = productDimDO.depCode
        val desCode = productDimDO.desCode

        val orderWide = OrderWideData(value.orderID, value.userID, value.productID, value.pubID,
          value.userMobile, value.userRegion, value.traffic, value.trafficGrade, value.trafficType,
          value.price, value.fee, value.hasActivity,
          value.adult, value.yonger, value.baby, value.ct,
          productLevel, productType, toursimType, depCode, desCode)

        //println(s"""orderWide=${JsonUtil.gObject2Json(orderWide)}""")
        out.collect(orderWide)

      }else{
        //println(s"""OrderWideBCFunction.productid[${orderProductID}] not match !""")
        val notMatch = "-1"

        val orderWide = OrderWideData(value.orderID, value.userID, value.productID, value.pubID,
          value.userMobile, value.userRegion, value.traffic, value.trafficGrade, value.trafficType,
          value.price, value.fee, value.hasActivity,
          value.adult, value.yonger, value.baby, value.ct,
          notMatch.toInt, notMatch, notMatch, notMatch, notMatch)
        //println(s"""orderWide=${JsonUtil.gObject2Json(orderWide)}""")
        out.collect(orderWide)
      }
    }


    //广播数据处理
    override def processBroadcastElement(value: ProductDimDO, ctx: BroadcastProcessFunction[OrderDetailData, ProductDimDO, OrderWideData]#Context, out: Collector[OrderWideData]): Unit = {
      val productBState :BroadcastState[String, ProductDimDO] = ctx.getBroadcastState(productMSDesc);
      products = products.:+(value)

      val key = value.productID
      productBState.put(key, value);
    }
  }
```



##### 异步IO方式

背景说明

```
不同于广播方式，异步IO方式核心思想是实时读取订单数据，异步方式加载其他资源数据（如mysql），然后和事实流数据整合形成宽表数据。
注释：具体代码参考 com.qf.bigdata.realtime.flink.streaming.etl.dw.orders.OrdersWideAsyncHander
```





###### 订单实时数据

```scala
/**
* 3 订单数据
*   原始明细数据转换操作
*/
val dStream :DataStream[String] = env.addSource(kafkaConsumer).setParallelism(QRealTimeConstant.DEF_LOCAL_PARALLELISM)

val orderDetailDStream :DataStream[OrderDetailData] = dStream.map(new OrderDetailDataMapFun())


/**
* 4 设置事件时间提取器及水位计算
*   固定范围的水位指定(注意时间单位)
*/
val ordersPeriodicAssigner = new OrdersPeriodicAssigner(QRealTimeConstant.FLINK_WATERMARK_MAXOUTOFORDERNESS)
    orderDetailDStream.assignTimestampsAndWatermarks(ordersPeriodicAssigner)
```



###### 维表数据提取

```
//单维表处理
val useLocalCache :Boolean = false
val dbPath = QRealTimeConstant.MYSQL_CONFIG_URL
val productDBQuery :DBQuery = createProductDBQuery()
val syncFunc = new DimProductAsyncFunction(dbPath, productDBQuery, useLocalCache)
1 数据库查询对象封装
2 要根据实际情况(维表变化频率),结合缓存机制提高处理的效率，另外也可防止意外突发情况(断网、mysql访问无响应等)
3 在异步IO中定时同步维度数据并构造宽表
```



数据库查询对象封装

```scala
/**
    * 构造旅游产品数据查询对象
    */
  def createProductDBQuery():DBQuery = {
    val sql = QRealTimeConstant.SQL_PRODUCT
    val schema = QRealTimeConstant.SCHEMA_PRODUCT
    val pk = "product_id";
    val tableProduct = QRealTimeConstant.MYDQL_DIM_PRODUCT

    new DBQuery(tableProduct, schema, pk, sql)
  }
```



数据库查询对象

```scala
/**
    * 数据源信息
    *
    * @param table
    * @param schema
    * @param pk
    * @param sql
    */
  case class DBQuery(table:String, schema:String, pk:String, sql:String)
```



###### 异步IO构造宽表

```
下面代码使用了google cache和redis、阿里数据库连接池Druid、定时调度ScheduledThreadPoolExecutor完成一个定时同步数据并结合缓存数据提供维表信息的功能，同时提供了异步处理功能，因为实现了RichAsyncFunction异步富操作函数，最后结合AsyncDataStream完成异步IO构造宽表。
强调一点：由于这里涉及代码及功能点相对较多，所以下面是主要局部代码，具体代码请参考项目
注释： com.qf.bigdata.realtime.flink.streaming.etl.dw.orders.OrdersWideAsyncHander
```



异步处理函数

```scala
/**
    * mysql异步读取函数
    */
  class DimProductAsyncFunction(dbPath:String, dbQuery:DBQuery, useLocalCache:Boolean) extends RichAsyncFunction[OrderDetailData,OrderWideData] {

    var pool :DBDruid = _
    val redisIP = "node243"
    val redisPort = 6379
    val redisPass = "qfqf"
    var redisClient : RedisClient = _
    var redisConn : StatefulRedisConnection[String,String] = _
    var redisCmd: RedisCommands[String, String] = _

    var localCache: Cache[String, String] = _
    var scheduled : ScheduledThreadPoolExecutor = _



    /**
      * 重新加载数据库数据
      */
    def reloadDB():Unit ={
      val dbResult = pool.execSQLJson(dbQuery.sql, dbQuery.schema, dbQuery.pk)
      if(useLocalCache){
        localCache.putAll(dbResult)
      }else{
        val key = dbQuery.table
        redisCmd.hmset(key, dbResult)
      }
    }


    /*
     * 初始化
     */
    override def open(parameters: Configuration): Unit = {
       println(s"""MysqlAsyncFunction open.time=${CommonUtil.formatDate4Def(new Date())}""")
       super.open(parameters)

        //数据库配置文件
        val dbProperties = PropertyUtil.readProperties(dbPath)

        val driver = dbProperties.getProperty(TravelConstant.FLINK_JDBC_DRIVER_MYSQL_KEY)
        val url = dbProperties.getProperty(TravelConstant.FLINK_JDBC_URL_KEY)
        val user = dbProperties.getProperty(TravelConstant.FLINK_JDBC_USERNAME_KEY)
        val passwd = dbProperties.getProperty(TravelConstant.FLINK_JDBC_PASSWD_KEY)

        //缓存连接
        pool = new DBDruid(driver, url, user, passwd)
        scheduled  = new ScheduledThreadPoolExecutor(2)
        if(useLocalCache){
          localCache = CacheBuilder.newBuilder.maximumSize(10000).expireAfterAccess(60L, TimeUnit.MINUTES).build[String,String]
        }else{
          redisClient = RedisClient.create(RedisURI.create(redisIP, redisPort))
          redisConn = redisClient.connect
          redisCmd = redisConn.sync
          redisCmd.auth(redisPass)
        }
        //数据初始化加载到缓存
        reloadDB()

        //定时更新缓存
        val initialDelay: Long = 0l
        val period :Long = 30l
       scheduled.scheduleAtFixedRate(new Runnable {
         override def run(): Unit = {
           reloadDB()
         }
       }, initialDelay, period, TimeUnit.SECONDS)
    }


    /**
      * 异步执行
      * @param input
      * @param resultFuture
      */
    override def asyncInvoke(input: OrderDetailData, resultFuture: ResultFuture[OrderWideData]): Unit = {
      try {
        println(s"""MysqlAsyncFunction invoke.time=${CommonUtil.formatDate4Def(new Date())}""")
        val orderProductID = input.productID
        var productInfo :String = ""
        if(useLocalCache){
          productInfo = localCache.getIfPresent(orderProductID)
        }else{
          val key = dbQuery.table
          val dataJson : util.Map[String,String] = redisCmd.hgetall(key)
          productInfo =  dataJson.getOrDefault(orderProductID,"")
        }
        val productRow : util.Map[String,Object] = JsonUtil.json2object(productInfo, classOf[util.Map[String,Object]])

        //product_id, product_level, product_type, departure_code, des_city_code, toursim_tickets_type
        val productLevel = productRow.get("product_level").toString.toInt
        val productType = productRow.get("product_type").toString
        val depCode = productRow.get("departure_code").toString
        val desCode = productRow.get("des_city_code").toString
        val toursimType = productRow.get("toursim_tickets_type").toString

        val orderWide = OrderWideData(input.orderID, input.userID, orderProductID, input.pubID,
          input.userMobile, input.userRegion, input.traffic, input.trafficGrade, input.trafficType,
          input.price, input.fee, input.hasActivity,
          input.adult, input.yonger, input.baby, input.ct,
          productLevel, productType, toursimType, depCode, desCode)
        println(s"""orderWide=${orderWide}""")

        val orderWides = List(orderWide)

        resultFuture.complete(orderWides)
      }catch {
        //注意：加入异常处理放置阻塞产生
        case ex: Exception => {
          println(s"""ex=${ex}""")
          logger.error("DimProductAsyncFunction.err:" + ex.getMessage)
          resultFuture.completeExceptionally(ex)
        }
      }
    }


    /**
      * 超时处理
      * @param input
      * @param resultFuture
      */
    override def timeout(input: OrderDetailData, resultFuture: ResultFuture[OrderWideData]): Unit = {
      println(s"""DimProductAsyncFunction timeout.time=${CommonUtil.formatDate4Def(new Date())}""")
      super.timeout(input, resultFuture)
    }

    /**
      * 关闭
      */
    override def close(): Unit = {
      println(s"""DimProductAsyncFunction close.time=${CommonUtil.formatDate4Def(new Date())}""")
      super.close()
      pool.close()
    }

  }
```



异步流调用

```scala
val useLocalCache :Boolean = false
val dbPath = QRealTimeConstant.MYSQL_CONFIG_URL
val productDBQuery :DBQuery = createProductDBQuery()
val syncFunc = new DimProductAsyncFunction(dbPath, productDBQuery, useLocalCache)

//异步流处理
val asyncDS :DataStream[OrderWideData] = AsyncDataStream.unorderedWait(orderDetailDStream, syncFunc, QRealTimeConstant.DYNC_DBCONN_TIMEOUT, TimeUnit.MINUTES, QRealTimeConstant.DYNC_DBCONN_CAPACITY)

```



#### 多维表宽表构造

```
对于需要使用多维表来构造宽表的情况，可以参考OrdersWideAsyncHander其中单独有一个方法，原理和异步IO里提到的类似，核心想法是构造map结构的多维表数据信息后定时查询同步。
强调一点维表数据量不能很大(当然维表数据量级较大的话会放在hbase之中)
```



### 第七节 实时明细输出

#### 背景说明

```
我们之前说过，对于在高并发或需要处理的业务逻辑较复杂的情况下，对于实时场景的数据计算处理性能产生一定影响，另外如果使用方需求查询实时明细数据或是其他的分组聚合方式，我们都是统计结果输出如何满足需求呢。所以在一些场景下需要我们将实时数据保存起来，当然是经过ETL之后的干净数据。
在实时场景下保存数据又可能会被使用方查询，那么选择时序库是比较好的方案，比如ES和 apache druid(当然druid并不是由Flink直接写入数据，而是通过将数据发送到kafka由druid作为数据源摄取)，这样在Flink的sink端我们介绍下这2种sink，另外作为聚合数据也可以输出到kafka或es之中。项目中根据不同业务需求会有很多类似的开发代码，下面示例仅仅作为展示示例，更多示例请参考项目代码，分别展示了输出数据到kafka和es
1 自定义sink(ES)  
2 输出到kafka，也就是kafka producer

注释：参考com.qf.bigdata.realtime.flink.streaming.etl.ods.UserLogsViewHandler,里面分别列举了以上2种sink。
```



#### 业务背景

##### 用户行为日志之页面浏览数据



创建页面浏览数据流

```
通过kafka数据通道读取全部行为日志经过过滤、ETL处理得到【页面浏览数据】
1 设置数据流的时间语义：事件时间
2 通过kafka配置文件消费消息通道数据
3 通过kafka数据反序列化产生行为日志数据流
4 使用过滤、ETL形成页面浏览日志数据流
5.1 自定义es-sink输出数据(flink有三方的es连接器，但如果你想使用es局部更新功能就需要使用自定义方式)
5.2 作为kafka producer将数据重新打回kafka(当然是不同topic)
```



```scala
//1 flink环境初始化使用事件时间做处理参考
val env: StreamExecutionEnvironment = FlinkHelper.createStreamingEnvironment(QRealTimeConstant.FLINK_CHECKPOINT_INTERVAL)
    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
    env.getConfig.setAutoWatermarkInterval(QRealTimeConstant.FLINK_WATERMARK_INTERVAL)

//2 kafka流式数据源
val consumerProperties :Properties = PropertyUtil.readProperties(QRealTimeConstant.KAFKA_CONSUMER_CONFIG_URL)

//创建消费者和消费策略
val schema:KafkaDeserializationSchema[UserLogData] = new UserLogsKSchema(fromTopic)
val kafkaConsumer : FlinkKafkaConsumer[UserLogData] = new FlinkKafkaConsumer[UserLogData](fromTopic, schema, consumerProperties)
    kafkaConsumer.setStartFromLatest()

//3 实时流数据集合操作
val dStream :DataStream[UserLogData] = env.addSource(kafkaConsumer).setParallelism(QRealTimeConstant.DEF_LOCAL_PARALLELISM)

//页面浏览
val viewDStream :DataStream[UserLogPageViewData] = dStream.filter(
      (log : UserLogData) => {
        log.action.equalsIgnoreCase(ActionEnum.PAGE_ENTER_H5.getCode) || log.action.equalsIgnoreCase(ActionEnum.PAGE_ENTER_NATIVE.getCode)
      }
    ).map(new UserLogPageViewDataMapFun())
```



###### 页面浏览数据

```scala
/**
    *用户行为日志页面浏览操作数据
    */
case class UserLogPageViewData(sid:String, userDevice:String, userDeviceType:String, 		os:String,userID:String,userRegion:String, userRegionIP:String, lonitude:String, 		latitude:String,manufacturer:String, carrier:String, networkType:String,             	 duration:String,action:String, eventType:String, ct:Long, targetID:String)
```



###### 自定义ES-Sink

```scala
/**
  * 用户行为日志页面浏览明细数据输出ES
  */
class UserLogsViewESSink(indexName:String) extends RichSinkFunction[UserLogPageViewData]{


  val logger :Logger = LoggerFactory.getLogger(this.getClass)

  var transportClient: PreBuiltTransportClient = _


  /**
    * 连接es集群
    * @param parameters
    */
  override def open(parameters: Configuration): Unit = {
    //flink与es网络通信参数设置(默认虚核)
    System.setProperty("es.set.netty.runtime.available.processors", "false")
    transportClient = ES6ClientUtil.buildTransportClient()
    super.open(parameters)
  }


  /**
    * Sink输出处理
    * @param value
    * @param context
    */
  override def invoke(value: UserLogPageViewData, context: SinkFunction.Context[_]): Unit = {
    try {
      //参数校验
      val viewData = JsonUtil.object2json(value)
      val checkResult: String = checkData(viewData)
      if (StringUtils.isNotBlank(checkResult)) {
        //日志记录
        logger.error("Travel.ESRecord.sink.checkData.err{}", checkResult)
        return
      }

      //记录信息
      val record :java.util.Map[String,String] = JsonUtil.json2object(viewData, classOf[java.util.Map[String,String]])

      //请求id
      val sid = value.sid

      //索引名称、类型名称
      handleData(indexName, indexName, sid, record)

    }catch{
      case ex: Exception => logger.error(ex.getMessage)
    }
  }

  /**
    * ES插入或更新数据
    * @param idxName
    * @param idxTypeName
    * @param esID
    * @param value
    */
  def handleData(idxName :String, idxTypeName :String, esID :String,
                 value: java.util.Map[String,String]): Unit ={
    val indexRequest = new IndexRequest(idxName, idxName, esID).source(value)
    val response = transportClient.prepareUpdate(idxName, idxName, esID)
      .setRetryOnConflict(QRealTimeConstant.ES_RETRY_NUMBER)
      .setDoc(value)
      .setUpsert(indexRequest)
      .get()
    if (response.status() != RestStatus.CREATED && response.status() != RestStatus.OK) {
      System.err.println("calculate es session record error!map:" + new ObjectMapper().writeValueAsString(value))
      throw new Exception("run exception:status:" + response.status().name())
    }
  }


  /**
    * 资源关闭
    */
  override def close() = {
    if (this.transportClient != null) {
      this.transportClient.close()
    }
  }
  
 ｝ 
```



###### 加工数据重发kafka

kafka反序列化

```scala
/**
  * 行为日志页面浏览数据(明细)kafka序列化
  */
class UserLogsPageViewKSchema (topic:String) extends KafkaSerializationSchema[UserLogPageViewData] with KafkaDeserializationSchema[UserLogPageViewData]{


  val gson : Gson = new Gson()


  /**
    * 反序列化
    * @param message
    * @return
    */
  override def deserialize(record: ConsumerRecord[Array[Byte], Array[Byte]]): UserLogPageViewData = {
    val key = record.key()
    val value = record.value()
    val log :UserLogPageViewData = gson.fromJson(new String(value), classOf[UserLogPageViewData])
    log
  }

  /**
    * 序列化
    * @param element
    * @return
    */
  override def serialize(element: UserLogPageViewData, timestamp: lang.Long): ProducerRecord[Array[Byte], Array[Byte]] = {
    val sid = element.sid
    val userDevice = element.userDevice
    val targetID = element.targetID
    val tmp = sid + userDevice+ targetID
    val key = CommonUtil.getMD5AsHex(tmp.getBytes)

    val value = JsonUtil.gObject2Json(element)
    new ProducerRecord[Array[Byte], Array[Byte]](topic, key.getBytes, value.getBytes)
  }

  override def isEndOfStream(nextElement: UserLogPageViewData): Boolean = {
    return false
  }

  override def getProducedType: TypeInformation[UserLogPageViewData] = {
    return TypeInformation.of(classOf[UserLogPageViewData])
  }


}
```



Flink kafka生产者

```scala
val kafkaSerSchema :KafkaSerializationSchema[UserLogPageViewData] = new UserLogsPageViewKSchema(toTopic)

val kafkaProductConfig = PropertyUtil.readProperties(QRealTimeConstant.KAFKA_PRODUCER_CONFIG_URL)
    val viewKafkaProducer = new FlinkKafkaProducer(
      toTopic,
      kafkaSerSchema,
      kafkaProductConfig,
      FlinkKafkaProducer.Semantic.AT_LEAST_ONCE)
    viewKafkaProducer.setWriteTimestampToKafka(true)

viewDStream.addSink(viewKafkaProducer)
```





### 第八节 实时数据统计

#### 背景说明

``` 
在实际工作中，不论离线还是实时场景统计报表、统计排名、去重统计是常用的计算方式，再细分又有开窗统计还是实时统计，其中就涉及开窗方式、窗口计算触发方式、延迟到达数据、测流输出、数据流状态保存等问题，下面我们来一一解决。
```



#### 基于窗口数据的统计

##### 订单事实数据统计

###### 需求点

```
解决以【userRegion:用户所属地区、traffic:出游交通方式】做维度，【orders:订单数量, maxFee:最高消费, totalFee:消费总数, members:旅游人次】做度量的订单固定间隔N分钟统计指标或近N分钟统计指标。
```

###### 技术分析

```
1 数据源
  基于订单事实明细数据来完成
  
2 结果为时间导向的计算需求，考虑以时间窗口进行统计计算 
  基于事件时间的滚动窗口(TumblingEventTimeWindows)统计，如每N分钟统计结果（实际事件发生时间）

3 数据输出
  如果结果要实时展示，那么可以结合grafana做展示，那么输出数据要输出到es、druid之中，当然它们也支持客户端交互式查询需求并有较好的性能。
  如果要高效的交互式查询，除了上面2种方案，也可以输出到clickhouse
```



窗口统计过程(局部代码)

详细代码参考：com.qf.bigdata.realtime.flink.streaming.agg.orders.OrdersDetailAggHandler

```scala
val aggDStream:DataStream[OrderDetailTimeAggDimMeaData] = orderDetailDStream.keyBy(
        (detail:OrderDetailData) => OrderDetailAggDimData(detail.userRegion, detail.traffic)
      )    .window(TumblingEventTimeWindows.of(Time.seconds(QRealTimeConstant.FLINK_WINDOW_SIZE)))
        .allowedLateness(Time.seconds(QRealTimeConstant.FLINK_ALLOWED_LATENESS))
        .aggregate(new OrderDetailTimeAggFun(), new OrderDetailTimeWindowFun())
```



聚合函数实现OrderDetailTimeAggFun

```scala
/**
    * 订单时间窗口预聚合函数
    */
  class OrderDetailTimeAggFun extends AggregateFunction[OrderDetailData, OrderDetailTimeAggMeaData, OrderDetailTimeAggMeaData] {
    /**
      * 创建累加器
      */
    override def createAccumulator(): OrderDetailTimeAggMeaData = {
      OrderDetailTimeAggMeaData(QRealTimeConstant.COMMON_NUMBER_ZERO, QRealTimeConstant.COMMON_NUMBER_ZERO,
        QRealTimeConstant.COMMON_NUMBER_ZERO, QRealTimeConstant.COMMON_NUMBER_ZERO)
    }

    /**
      * 累加开始
      */
    override def add(value: OrderDetailData, accumulator: OrderDetailTimeAggMeaData): OrderDetailTimeAggMeaData = {
      val orders = QRealTimeConstant.COMMON_NUMBER_ONE + accumulator.orders
      var maxFee = accumulator.maxFee.max(value.fee)
      val totalFee = value.fee + accumulator.totalFee
      val orderMembers = value.adult.toInt + value.yonger.toInt + value.baby.toInt
      val members = orderMembers + accumulator.members

      OrderDetailTimeAggMeaData(orders, maxFee, totalFee, members)
    }

    /**
      * 获取结果数据
      */
    override def getResult(accumulator: OrderDetailTimeAggMeaData): OrderDetailTimeAggMeaData = {
      println(s"""OrderDetailTimeAggFun.getResult[${CommonUtil.formatDate4Def(new Date())}] ===> """)
      accumulator
    }

    /**
      * 合并中间数据
      */
    override def merge(a: OrderDetailTimeAggMeaData, b: OrderDetailTimeAggMeaData): OrderDetailTimeAggMeaData = {
      val orders = a.orders + a.orders
      var maxFee = a.maxFee.max(b.maxFee)
      val totalFee = a.totalFee + b.totalFee
      val members = a.members + b.members
      OrderDetailTimeAggMeaData(orders, maxFee, totalFee, members)
    }
  }
```



窗口函数输出统计结果

```scala
/**
    * 订单时间窗口输出函数
    */
  class OrderDetailTimeWindowFun extends WindowFunction[OrderDetailTimeAggMeaData, OrderDetailTimeAggDimMeaData, OrderDetailAggDimData, TimeWindow]{
    override def apply(key: OrderDetailAggDimData, window: TimeWindow, input: Iterable[OrderDetailTimeAggMeaData], out: Collector[OrderDetailTimeAggDimMeaData]): Unit = {
      //分组维度
      val userRegion = key.userRegion
      val traffic = key.traffic

      //度量计算
      var outOrders = QRealTimeConstant.COMMON_NUMBER_ZERO
      var outMaxFee = QRealTimeConstant.COMMON_NUMBER_ZERO
      var outFees = QRealTimeConstant.COMMON_NUMBER_ZERO
      var outMembers = QRealTimeConstant.COMMON_NUMBER_ZERO
      for(meaData: OrderDetailTimeAggMeaData <- input){
        outOrders = outOrders + meaData.orders
        outMaxFee = outMaxFee.max(meaData.maxFee)
        outFees = outFees + meaData.totalFee
        outMembers = outMembers + meaData.members
      }
      val outAvgFee = outFees / outOrders

      //窗口时间
      val startWindowTime = window.getStart
      val endWindowTime = window.getEnd

      val owDMData = OrderDetailTimeAggDimMeaData(userRegion, traffic, startWindowTime, endWindowTime,outOrders, outMaxFee, outFees, outMembers, outAvgFee)
      out.collect(owDMData)
    }
  }
```



##### 订单宽表统计

###### 需求点

```
解决以【productType:产品种类、toursimType:产品类型】做维度，【orders:订单数量, maxFee:最高消费, totalFee:消费总数, members:旅游人次】做度量的订单固定间隔N分钟统计指标或近N分钟统计指标。
```

###### 技术分析

```
1 数据源
  考虑到聚合维度的扩展性，可以基于订单宽表明细数据来完成而不是订单事实数据
  
2 结果为时间导向的计算需求，考虑以时间窗口进行统计计算 
(1) 基于事件时间的滚动窗口(TumblingEventTimeWindows)统计，如每N分钟统计结果（实际事件发生时间）
(2) 基于事件时间的滑动窗口(SlidingEventTimeWindows)统计，如近N分钟统计结果（实际事件发生时间）
(3) 基于处理时间的滚动窗口(TumblingProcessingTimeWindows)统计，如每N分钟统计结果（任务处理节点机器时间）
(4) 基于处理时间的滑动窗口(SlidingProcessingTimeWindows)统计，如每N分钟统计结果（任务处理节点机器时间）
窗口聚合可以使用reduce、aggregate、process、max|sum|min等函数，但reduce和aggregate有预聚合功能所以比process更高效，比max等更强大灵活，所以aggregate和reduce相对使用较多。

3 数据输出
  如果结果要实时展示，那么可以结合grafana做展示，那么输出数据要输出到es、druid之中，当然它们也支持客户端交互式查询需求并有较好的性能。
  如果要高效的交互式查询，除了上面2种方案，也可以输出到clickhouse
```



窗口统计过程(局部代码)

详细代码参考：com.qf.bigdata.realtime.flink.streaming.agg.orders.OrdersWideTimeAggHandler

```scala
val aggDStream:DataStream[OrderWideTimeAggDimMeaData] = orderWideGroupDStream.keyBy({
        (wide:OrderWideData) => OrderWideAggDimData(wide.productType, wide.toursimType)
      })
        .window(TumblingEventTimeWindows.of(Time.seconds(QRealTimeConstant.FLINK_WINDOW_SIZE)))
        .allowedLateness(Time.seconds(QRealTimeConstant.FLINK_ALLOWED_LATENESS))
        .aggregate(new OrderWideTimeAggFun(), new OrderWideTimeWindowFun())
```



聚合函数aggregate之AggregateFunction实现

```scala
/**
    * 订单宽表时间窗口预聚合函数
    */
  class OrderWideTimeAggFun extends AggregateFunction[OrderWideData, OrderWideTimeAggMeaData, OrderWideTimeAggMeaData] {
    /**
      * 创建累加器
      */
    override def createAccumulator(): OrderWideTimeAggMeaData = {
      OrderWideTimeAggMeaData(QRealTimeConstant.COMMON_NUMBER_ZERO, QRealTimeConstant.COMMON_NUMBER_ZERO,
        QRealTimeConstant.COMMON_NUMBER_ZERO, QRealTimeConstant.COMMON_NUMBER_ZERO)
    }

    /**
      * 累加开始
      */
    override def add(value: OrderWideData, accumulator: OrderWideTimeAggMeaData): OrderWideTimeAggMeaData = {
      val orders = QRealTimeConstant.COMMON_NUMBER_ONE + accumulator.orders
      var maxFee = accumulator.maxFee.max(value.fee)
      val totalFee = value.fee + accumulator.totalFee
      val orderMembers = value.adult.toInt + value.yonger.toInt + value.baby.toInt
      val members = orderMembers + accumulator.members
      OrderWideTimeAggMeaData(orders, maxFee, totalFee, members)
    }

    /**
      * 获取结果数据
      */
    override def getResult(accumulator: OrderWideTimeAggMeaData): OrderWideTimeAggMeaData = {
      accumulator
    }

    /**
      * 合并中间数据
      */
    override def merge(a: OrderWideTimeAggMeaData, b: OrderWideTimeAggMeaData): OrderWideTimeAggMeaData = {
      val orders = a.orders + a.orders
      var maxFee = a.maxFee.max(b.maxFee)
      val totalFee = a.totalFee + b.totalFee
      val members = a.members + b.members
      OrderWideTimeAggMeaData(orders, maxFee, totalFee, members)
    }
  }
```



聚合函数aggregate之WindowFunction实现

```scala
/**
    * 订单宽表时间窗口输出函数
    */
  class OrderWideTimeWindowFun extends WindowFunction[OrderWideTimeAggMeaData, OrderWideTimeAggDimMeaData, OrderWideAggDimData, TimeWindow]{
    override def apply(key: OrderWideAggDimData, window: TimeWindow, input: Iterable[OrderWideTimeAggMeaData], out: Collector[OrderWideTimeAggDimMeaData]): Unit = {
      //分组维度
      val productType = key.productType
      val toursimType = key.toursimType

      //度量计算
      var outOrders = QRealTimeConstant.COMMON_NUMBER_ZERO
      var outMaxFee = QRealTimeConstant.COMMON_NUMBER_ZERO
      var outFees = QRealTimeConstant.COMMON_NUMBER_ZERO
      var outMembers = QRealTimeConstant.COMMON_NUMBER_ZERO
      for(meaData :OrderWideTimeAggMeaData <- input){
        outOrders = outOrders + meaData.orders
        outMaxFee = outMaxFee.max(meaData.maxFee)
        outFees = outFees + meaData.totalFee
        outMembers = outMembers + meaData.members
      }
      val outAvgFee = outFees / outOrders

      //窗口时间
      val startWindowTime = window.getStart
      val endWindowTime = window.maxTimestamp()

      val owDMData = OrderWideTimeAggDimMeaData(productType, toursimType, startWindowTime, endWindowTime,outOrders, outMaxFee, outFees, outMembers, outAvgFee)
      out.collect(owDMData)
    }
  }
```



统计结果输出kafka供下游处理

```scala
//kafka数据序列化
val orderWideGroupKSerSchema = new OrderWideGroupKSchema(toTopic)

//kafka配置信息
val kafkaProductConfig = PropertyUtil.readProperties(QRealTimeConstant.KAFKA_PRODUCER_CONFIG_URL)

//kafka生产者
val travelKafkaProducer = new FlinkKafkaProducer(
        toTopic,
        orderWideGroupKSerSchema,
        kafkaProductConfig,
        FlinkKafkaProducer.Semantic.AT_LEAST_ONCE)

//5 加入kafka摄入时间
travelKafkaProducer.setWriteTimestampToKafka(true)
aggDStream.addSink(travelKafkaProducer)
```



##### 订单统计排名

###### 需求点

```
有了分类统计结果就可以进行排名操作，比如各种热门排名
```

###### 技术分析

```
1 数据源
  订单统计结果
  
2 窗口内的数据处理(ProcessWindowFunction)，排序比较逻辑，采用列表状态维护排名topN

3 数据输出
  如果结果要实时展示，那么可以结合grafana做展示，那么输出数据要输出到es、druid之中，当然它们也支持客户端交互式查询需求并有较好的性能。
  如果要高效的交互式查询，除了上面2种方案，也可以输出到clickhouse
```



窗口统计过程(局部代码)

详细代码参考：com.qf.bigdata.realtime.flink.streaming.agg.orders.OrdersTopnStatisHandler

```scala
/**
      * 6 topN排序
      * Sorted的数据结构TreeSet或者是优先级队列PriorityQueue , TreeSet 实现原理是红黑树，优先队列实现原理就是最大/最小堆，
      * 这两个都可以满足需求，但要如何选择？红黑树的时间复杂度是logN，而堆的构造复杂度是N, 读取复杂度是1，
      * 但是我们这里需要不断的做数据插入那么就涉及不断的构造过程，相对而言选择红黑树比较好(其实flink sql内部做topN也是选择红黑树类型的TreeMap)
      */
val topNDStream:DataStream[OrderTrafficDimMeaData] = aggDStream.keyBy(
    (detail:OrderTrafficDimMeaData) => {
        OrderTrafficDimData(detail.productID, detail.traffic)
    }
)
.window(TumblingEventTimeWindows.of(Time.seconds(QRealTimeConstant.FLINK_WINDOW_SIZE)))
      .allowedLateness(Time.seconds(QRealTimeConstant.FLINK_ALLOWED_LATENESS))
      .process(new OrderTopNKeyedProcessFun(topN))

```



窗口处理函数ProcessWindowFunction

```scala
/**
    * 基于实时流数据的订单综合统计
    */
class OrderTopNKeyedProcessFun(topN:Long) extends ProcessWindowFunction[OrderTrafficDimMeaData, OrderTrafficDimMeaData, OrderTrafficDimData, TimeWindow] {

    //状态描述名称
    val ORDER_TOPN_DESC = "ORDER_TOPN_DESC"
    var orderTopNState :ListState[OrderTrafficDimMeaData] = _
    var orderTopNStateDesc :ListStateDescriptor[OrderTrafficDimMeaData] = _


    /**
      * 初始化
      * @param parameters
      */
    override def open(parameters: Configuration): Unit = {

      //状态数据：订单数量
      orderTopNStateDesc = new ListStateDescriptor[OrderTrafficDimMeaData](ORDER_TOPN_DESC, createTypeInformation[OrderTrafficDimMeaData])
      orderTopNState = this.getRuntimeContext.getListState(orderTopNStateDesc)
    }


  /**
    * 处理数据
    */
    override def process(key: OrderTrafficDimData, context: Context, elements: Iterable[OrderTrafficDimMeaData], out: Collector[OrderTrafficDimMeaData]): Unit = {
      //原始数据
      val productID = key.productID
      val traffic = key.traffic

      //排序比较
      val topNContainer = new java.util.TreeSet[OrderTrafficDimMeaData](new OrderTopnComparator())

      for(element :OrderTrafficDimMeaData <- elements){
         val orders = element.orders
         val members = element.members
         val totalFee = element.totalFee
         val startWindowTime = element.startWindowTime
         val endWindowTime = element.endWindowTime

         val value = new OrderTrafficDimMeaData(productID, traffic, startWindowTime, endWindowTime,orders, members,totalFee)
         if(!topNContainer.isEmpty){
           if(topNContainer.size() >= topN){
             val first : OrderTrafficDimMeaData = topNContainer.first()
             val result = topNContainer.comparator().compare(first, value)
             if(result < 0){
               topNContainer.pollFirst()
               topNContainer.add(value)
             }
           }else{
             topNContainer.add(value)
           }
           topNContainer.add(value)
         }else{
           topNContainer.add(value)
         }
       }
    }
  }
```



##### 订单统计(条件触发器)

###### 需求点

```
1 数据源
  基于订单事实明细数据来完成
  
2 结果为时间导向的计算需求，考虑以时间窗口进行统计计算，但如果时间周期相对较长时（30分钟以上），此时又有需求要求在此期间输出数据，表现为特定条件时触发输出(大家可以回想下采集框架flume) 如数据量>m，时间间隔输出
  基于事件时间的滚动窗口(TumblingEventTimeWindows)统计，如每N分钟统计结果（实际事件发生时间）

3 数据输出
  如果结果要实时展示，那么可以结合grafana做展示，那么输出数据要输出到es、druid之中，当然它们也支持客户端交互式查询需求并有较好的性能。
  如果要高效的交互式查询，除了上面2种方案，也可以输出到clickhouse
```



###### 技术分析

```
1 数据源
  订单统计结果
  
2 根据需求来看仅仅依靠Flink提供的默认窗口方式不足以满足(本质是内置的窗口触发器)，故需要自定义实现触发器来满足数据量和时间条件上的先后关系Trigger

```



窗口统计过程(局部代码)

详细代码参考：com.qf.bigdata.realtime.flink.streaming.agg.orders.OrdersDetailAggHandler之handleOrdersAggWindowWithTriggerJob

```scala
 /**
  * 5 开窗聚合操作
 */
val windowCount = 10000
val maxCount = 100
val aggDStream:DataStream[OrderDetailTimeAggDimMeaData] = orderDetailDStream.keyBy(
     (detail:OrderDetailData) => OrderDetailAggDimData(detail.userRegion, detail.traffic)
 )
.window(TumblingEventTimeWindows.of(Time.minutes(QRealTimeConstant.FLINK_WINDOW_SIZE)))
        .trigger(new OrdersStatisTrigger(10, 100l))
        .allowedLateness(Time.seconds(QRealTimeConstant.FLINK_ALLOWED_LATENESS))
        .aggregate(new OrderDetailTimeAggFun(), new OrderDetailTimeWindowFun())
```



自定义触发器

```scala
/**
  * 旅游产品订单业务自定义触发器
  */
class OrdersStatisTrigger(maxCount:Long, maxInterval :Long) extends Trigger[OrderDetailData, TimeWindow]{

  val logger :Logger = LoggerFactory.getLogger("OrdersAggTrigger")

  var accCount:Long = 1l

  override def onElement(element: OrderDetailData, timestamp: Long, window: TimeWindow, ctx: Trigger.TriggerContext): TriggerResult = {
    logger.info("===OrdersStatisTrigger.onElement===window start = {}, window end = {}", window.getStart, window.getEnd)

    ctx.registerEventTimeTimer(window.maxTimestamp)
    if(accCount >= maxCount ){
      accCount = 0
      return TriggerResult.FIRE
    }else{
      accCount = accCount + 1
    }
    return TriggerResult.CONTINUE
  }

  override def onProcessingTime(time: Long, window: TimeWindow, ctx: Trigger.TriggerContext): TriggerResult = {
    return TriggerResult.FIRE;
  }

  override def onEventTime(time: Long, window: TimeWindow, ctx: Trigger.TriggerContext): TriggerResult = {
    return TriggerResult.CONTINUE;
  }

  override def clear(window: TimeWindow, ctx: Trigger.TriggerContext): Unit = {
    ctx.deleteProcessingTimeTimer(window.maxTimestamp)
  }

}
```



##### 订单统计(PUV)

###### 需求点

```
解决以【userRegion:用户所属地区、traffic:出游交通方式】做维度，【orders:订单数量, maxFee:最高消费, totalFee:消费总数, members:旅游人次】做度量的订单固定间隔N分钟统计指标或近N分钟统计指标。
```

###### 技术分析

```
1 数据源
  基于订单事实明细数据来完成
  
2 结果为时间导向的计算需求，考虑以时间窗口进行统计计算 
  基于事件时间的滚动窗口(TumblingEventTimeWindows)统计，如每N分钟统计结果（实际事件发生时间）
  关键是：UV如何解决，需要维护数据状态

3 数据输出
  如果结果要实时展示，那么可以结合grafana做展示，那么输出数据要输出到es、druid之中，当然它们也支持客户端交互式查询需求并有较好的性能。
  如果要高效的交互式查询，除了上面2种方案，也可以输出到clickhouse
```



窗口统计过程(局部代码)

详细代码参考：com.qf.bigdata.realtime.flink.streaming.agg.orders.OrdersStatisHandler

```scala
val statisDStream:DataStream[OrderDetailStatisData] = orderDetailDStream.keyBy(
(detail:OrderDetailData) => {
  val hourTime = CommonUtil.formatDate4Timestamp(detail.ct, QRealTimeConstant.FORMATTER_YYYYMMDDHH)
   OrderDetailSessionDimData(detail.traffic, hourTime)})
.window(TumblingEventTimeWindows.of(Time.minutes(QRealTimeConstant.FLINK_WINDOW_MAX_SIZE)))
.trigger(new OrdersStatisCountTrigger(maxCount))
.process(new OrderStatisWindowProcessFun())
```



数据状态维护

```scala
class OrderStatisWindowProcessFun extends ProcessWindowFunction[OrderDetailData, OrderDetailStatisData, OrderDetailSessionDimData, TimeWindow]{

    //状态描述名称
    val ORDER_STATE_USER_DESC = "ORDER_STATE_USER_DESC"
    var usersState :ValueState[mutable.Set[String]] = _
    var usersStateDesc :ValueStateDescriptor[mutable.Set[String]] = _

    val ORDER_STATE_ORDERS_DESC = "ORDER_STATE_ORDERS_DESC"
    var ordersAccState :ValueState[OrderAccData] = _
    var ordersAccStateDesc :ValueStateDescriptor[OrderAccData] = _



    /**
      * 连接资源初始化(如果需要)
      * @param parameters
      */
    override def open(parameters: Configuration): Unit = {
      //状态数据：订单UV
      usersStateDesc = new ValueStateDescriptor[mutable.Set[String]](ORDER_STATE_USER_DESC, createTypeInformation[mutable.Set[String]])
      usersState = this.getRuntimeContext.getState(usersStateDesc)

      //状态数据：订单度量(订单总数量、订单总费用)
      ordersAccStateDesc = new ValueStateDescriptor[OrderAccData](ORDER_STATE_ORDERS_DESC, createTypeInformation[OrderAccData])
      ordersAccState = this.getRuntimeContext.getState(ordersAccStateDesc)
    }




    /**
      * 数据处理
      * @param value
      * @param ctx
      * @param out
      */
    override def process(key: OrderDetailSessionDimData, context: Context, elements: Iterable[OrderDetailData], out: Collector[OrderDetailStatisData]): Unit = {
      //订单分组维度：出行方式、事件时间
      val traffic = key.traffic
      val hourTime = key.hourTime

      //时间相关
      val curWatermark :Long = context.currentWatermark
      val ptTime:String = CommonUtil.formatDate4Timestamp(context.currentProcessingTime, QRealTimeConstant.FORMATTER_YYYYMMDDHHMMSS)


      //状态相关数据
      var userKeys :mutable.Set[String] = usersState.value
      var ordersAcc :OrderAccData =  ordersAccState.value
      if(null == ordersAcc){
        ordersAcc = new OrderAccData(QRealTimeConstant.COMMON_NUMBER_ZERO, QRealTimeConstant.COMMON_NUMBER_ZERO)
      }
      if(null == userKeys){
        userKeys = mutable.Set[String]()
      }

      //数据聚合处理
      var totalOrders :Long = ordersAcc.orders
      var totalFee :Long = ordersAcc.totalFee
      var usersCount :Long = userKeys.size
      for(element <- elements){
        //度量数据处理
        val userID = element.userID
        totalOrders +=  1
        totalFee += element.fee

        //UV判断
        if(!userKeys.contains(userID)){
          userKeys += userID
        }
        usersCount = userKeys.size
      }

      val orderDetailStatis = new OrderDetailStatisData(traffic, hourTime, totalOrders, usersCount, totalFee, ptTime)
      //println(s"""orderDetailStatis=${orderDetailStatis}""")
      out.collect(orderDetailStatis)

      //状态数据更新
      usersState.update(userKeys)
      ordersAccState.update(new OrderAccData(totalOrders, totalFee))
    }


    /**
      * 状态数据清理
      * @param context
      */
    override def clear(context: Context): Unit = {
      usersState.clear()
      ordersAccState.clear()
    }
  }
```



#### 实时数据统计(非窗口统计)

##### 订单事实数据统计(自定义处理)

###### 需求点

```
解决以【productType:产品种类、toursimType:产品类型】做维度，【startWindowTime:开始时间, endWindowTime:结束时间, orders:订单数, users:用户人数, totalFee:消费总数】做度量的自定义触发、计算处理。

```

###### 技术分析

```
1 数据源
  基于订单事实明细数据来完成
  
2 结果为时间导向的计算需求，考虑以时间窗口进行统计计算 
  基于事件时间的滚动窗口(TumblingEventTimeWindows)统计，如每N分钟统计结果（实际事件发生时间）

3 数据输出
  如果结果要实时展示，那么可以结合grafana做展示，那么输出数据要输出到es、druid之中，当然它们也支持客户端交互式查询需求并有较好的性能。
  如果要高效的交互式查询，除了上面2种方案，也可以输出到clickhouse
```



窗口统计过程(局部代码)

详细代码参考：com.qf.bigdata.realtime.flink.streaming.agg.orders.OrdersCustomerStatisHandler

```scala
/**
* 7综合统计
*/
val statisDStream:DataStream[OrderWideCustomerStatisData] = orderWideDStream.keyBy(
	(wide:OrderWideData) => {OrderWideAggDimData(wide.productType, wide.toursimType)}
)
.process(new OrderCustomerStatisKeyedProcessFun(maxCount, maxInterval))

```



处理逻辑与状态维护

```scala
/**
    * 基于实时流数据的订单综合统计
    */
  class OrderCustomerStatisKeyedProcessFun(maxCount :Long, maxInterval :Long) extends KeyedProcessFunction[OrderWideAggDimData, OrderWideData, OrderWideCustomerStatisData] {

    //状态描述名称
    val CUSTOMER_ORDER_STATE_USER_DESC = "CUSTOMER_ORDER_STATE_USER_DESC"
    var customerUserState :ValueState[mutable.Set[String]] = _
    var customerUserStateDesc :ValueStateDescriptor[mutable.Set[String]] = _

    val CUSTOMER_ORDER_STATE_ORDERS_DESC = "CUSTOMER_ORDER_STATE_ORDERS_DESC"
    var customerOrdersAccState :ValueState[OrderAccData] = _
    var customerOrdersAccStateDesc :ValueStateDescriptor[OrderAccData] = _

    val CUSTOMER_ORDER_STATE_PROCESS_DESC = "CUSTOMER_ORDER_STATE_PROCESS_DESC"
    var customerProcessState :ValueState[QProcessWindow] = _
    var customerProcessStateDesc :ValueStateDescriptor[QProcessWindow] = _


    /**
      * 初始化
      * @param parameters
      */
    override def open(parameters: Configuration): Unit = {

      //状态数据：订单UV
      customerUserStateDesc = new ValueStateDescriptor[mutable.Set[String]](CUSTOMER_ORDER_STATE_USER_DESC, createTypeInformation[mutable.Set[String]])
      customerUserState = this.getRuntimeContext.getState(customerUserStateDesc)

      //状态数据：订单度量(订单总数量、订单总费用)
      customerOrdersAccStateDesc = new ValueStateDescriptor[OrderAccData](CUSTOMER_ORDER_STATE_ORDERS_DESC, createTypeInformation[OrderAccData])
      customerOrdersAccState = this.getRuntimeContext.getState(customerOrdersAccStateDesc)

      //处理时间
      customerProcessStateDesc = new ValueStateDescriptor[QProcessWindow](CUSTOMER_ORDER_STATE_PROCESS_DESC, createTypeInformation[QProcessWindow])
      customerProcessState = this.getRuntimeContext.getState(customerProcessStateDesc)

    }

    /**
      * 处理数据
      * @param value
      * @param ctx
      * @param out
      */
    override def processElement(value: OrderWideData, ctx: KeyedProcessFunction[OrderWideAggDimData, OrderWideData, OrderWideCustomerStatisData]#Context, out: Collector[OrderWideCustomerStatisData]): Unit = {
      //原始数据
      val productType = value.productType
      val toursimType = value.toursimType
      val userID = value.userID
      val fee = value.fee

      //记录时间
      val curProcessTime = ctx.timerService().currentProcessingTime()
      val maxIntervalTimestamp :Long = Time.of(maxInterval,TimeUnit.MINUTES).toMilliseconds
      var nextProcessingTime = TimeWindow.getWindowStartWithOffset(curProcessTime, 0, maxIntervalTimestamp) + maxIntervalTimestamp

      //时间触发条件：当前处理时间到达或超过上次处理时间+间隔后触发本次窗口操作
      if(customerProcessState.value() == null){
        customerProcessState.update(new QProcessWindow(curProcessTime, curProcessTime))
        ctx.timerService().registerProcessingTimeTimer(nextProcessingTime)
      }
      val qProcessWindow :QProcessWindow = customerProcessState.value()
      if(curProcessTime >= qProcessWindow.end){
        qProcessWindow.end = curProcessTime
      }
      customerProcessState.update(qProcessWindow)
      val startWindowTime = qProcessWindow.start
      val endWindowTime = qProcessWindow.end

      //PV等度量统计
      var ordersAcc :OrderAccData =  customerOrdersAccState.value
      if(null == ordersAcc){
        ordersAcc = new OrderAccData(QRealTimeConstant.COMMON_NUMBER_ZERO, QRealTimeConstant.COMMON_NUMBER_ZERO)
      }
      var totalOrders :Long = ordersAcc.orders + 1
      var totalFee :Long = ordersAcc.totalFee + fee
      customerOrdersAccState.update(new OrderAccData(totalOrders, totalFee))

      //UV判断
      var userKeys :mutable.Set[String] = customerUserState.value
      if(null == userKeys){
        userKeys = mutable.Set[String]()
      }
      if(!userKeys.contains(userID)){
        userKeys += userID
      }
      val users = userKeys.size
      customerUserState.update(userKeys)

      //数量触发条件：maxCount

      if(totalOrders >= maxCount){
        val orderDetailStatisData = OrderWideCustomerStatisData(productType, toursimType, startWindowTime, endWindowTime,totalOrders, users, totalFee)

        out.collect(orderDetailStatisData)
        customerOrdersAccState.clear()
        customerUserState.clear()
      }
    }
```





(1) 运营类指标：实时数据报表
用户粘性统计： 
	用户启动数据统计(以APP启动或WEB登录为准)
	用户启动数据环比
	
分时段累计日活DAU(可按具体业务划分：旅游产品、票务、酒店住宿等)
	基于小时级别逐步统计DAU（可基于Redis|ES）
	
	
(2) 主营业务之数据实时分析
实时业务数据聚合统计(可按具体业务(旅游产品、票务、酒店住宿等)下的子业务进行划分)
	基于小时级别进行开窗统计，实时结果输出Sink（可基于Redis|ES|Druid）
	示例：
		实时统计旅游产品的业务数据PV、UV、费用等等
		实时统计旅游产品的浏览日志PV、UV等等
		实时旅游产品的环比
	  
实时业务数据多维聚合统计
	基于小时级别进行开窗统计，基于kylin进行多维数据分析
	示例：
	多维度【用户性别、用户年龄段、用户地区、实时时段(小时级别，需要二次加工)】
		实时统计旅游产品的业务数据PV、UV、费用等等
		实时统计旅游产品的浏览日志PV、UV等等



(1) 个性化推荐营销(实时场景：基于用户的实时偏好)
	例如用户浏览旅游产品、酒店信息时可通过相似用户进行相关推荐或将实时热门产品进行实时推荐
	
(2) 实时场景下的活动效果
	实时统计优惠活动下的产品浏览统计、下单统计

(3) 实时场景下的排名及统计效果
	实时场景下的某些维度下的分类统计和TopN
	例如
		旅游产品下的不同时段内旅游产品类型(周边游等)的PV、UV统计及排名
		旅游产品下的不同时段内评价统计及排名
		旅游产品下的不同时段内分享统计及排名
		所选酒店的不同时段内旅游产品类型(周边游等)的PV、UV统计及排名
		所选酒店的不同时段内评价统计及排名
		所选酒店的不同时段内分享统计及排名





### 第九节 实时数据采集

#### 背景说明

```
在实际工作中，可能会遇到要求数据能够实时的采集下来或者在高并发场景下业务逻辑以异步方式集合消息通道来进行数据处理，这样就涉及一个问题数据如何实时采集，虽然有像flume这样的采集框架，但它基于数据量大小和时间间隔的方式不一定能满足实时采集要求，所以消息通道+消息消费落地这种技术方案可以解决这类问题，数据通道可以采用kafka，消息消费可以采用Flink、SparkStreaming等框架完成。另外实时采集到的数据还可以校对实时计算结果或进行补救措施。
```



#### 用户启动日志实时采集

##### 需求点

```
用户启动日志的实时采集落地(HDFS)
```



##### 技术分析

```
1 数据源
  基于订单事实明细数据来完成
  
2 结果为时间导向的计算需求，考虑以时间窗口进行统计计算 
  基于事件时间的滚动窗口(TumblingEventTimeWindows)统计，如每N分钟统计结果（实际事件发生时间）

3 数据输出
  如果结果要实时展示，那么可以结合grafana做展示，那么输出数据要输出到es、druid之中，当然它们也支持客户端交互式查询需求并有较好的性能。
  如果要高效的交互式查询，除了上面2种方案，也可以输出到clickhouse
```



实时数据采集落地过程(局部代码)

详细代码参考：com.qf.bigdata.realtime.flink.streaming.etl.ods.UserLogsLaunchBatchRec

```scala
//数据实时采集落地

//数据落地路径
val outputPath :Path = new Path(output)
//落地大小阈值
val maxPartSize = 1024l * 1024l * maxSize
//落地时间间隔
val rolloverInl = TimeUnit.MINUTES.toMillis(rolloverInterval)
//无数据间隔时间
val inactivityInl = TimeUnit.MINUTES.toMillis(inactivityInterval)
//分桶检查点时间间隔
val bucketCheckInl = TimeUnit.MINUTES.toMillis(bucketCheckInterval)

//落地策略
val rollingPolicy :DefaultRollingPolicy[String,String] = DefaultRollingPolicy.create()
.withRolloverInterval(rolloverInl)
.withInactivityInterval(inactivityInl)
.withMaxPartSize(maxPartSize)
.build()

//数据分桶分配器
val bucketAssigner :BucketAssigner[String,String] = new DateTimeBucketAssigner(QRealTimeConstant.FORMATTER_YYYYMMDDHH)

//输出sink
val hdfsSink: StreamingFileSink[String] = StreamingFileSink
.forRowFormat(outputPath, new SimpleStringEncoder[String]("UTF-8"))
.withBucketAssigner(bucketAssigner)
.withRollingPolicy(rollingPolicy)
.withBucketCheckInterval(bucketCheckInl)
.build()

launchRowDStream.addSink(hdfsSink)

```































附录：

1 旅游研究院&携程大数据报告 <http://www.ctaweb.org/html/2018-6/2018-6-29-9-4-22023.html>

2 旅游大数据

<http://www.1000fun.com/productpage/5>

3 阿里云智能旅游解决方案

<http://www.qingtaibj.com/travel.jsp>

4 携程数据分析

<https://www.afenxi.com/24468.html>

5 携程实时用户数据采集与分析

<https://blog.csdn.net/imgxr/article/details/80129726>